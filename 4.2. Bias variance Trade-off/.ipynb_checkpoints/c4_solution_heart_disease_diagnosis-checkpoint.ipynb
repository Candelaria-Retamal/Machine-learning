{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heart disease diagnosis\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Evaluate \"most-frequent\" baseline\n",
    "\n",
    "> **Exercise**: Load and split the `heart-disease.csv` data into 70-30 train/test sets - make sure to keep the same proportion of classes by setting `stratify`. Evaluate the accuracy of the \"most-frequent\" baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "data_df = pd.read_csv(\"c4_heart-disease.csv\")\n",
    "\n",
    "# First five rows\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classes:\", data_df.disease.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create X/y variables\n",
    "X = data_df.drop(\"disease\", axis=1)\n",
    "y = data_df.disease\n",
    "\n",
    "# Split into train/test sets\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.3, random_state=0\n",
    ")\n",
    "print(\"Train:\", X_tr.shape, y_tr.shape)\n",
    "print(\"Test:\", X_te.shape, y_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(None, y_tr)\n",
    "print(\"Test accuracy: {:.2f}%\".format(100 * dummy.score(None, y_te)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"most-frequent\" baseline accuracy is around 54%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise - Evaluate k-NN baseline\n",
    "---\n",
    "\n",
    "> **Exercise**: Tune a k-NN classifier using grid search with **stratified 10-fold** cross-validation\n",
    "> * Number of neighbors k\n",
    "> * Distance metric - $L_{1}$ or $L_{2}$\n",
    "> * Weighting strategy - uniform or by distance\n",
    ">\n",
    "> Refit the best estimator on the whole train set and report the test accuracy.\n",
    "\n",
    "Dataset documentation: http://archive.ics.uci.edu/ml/datasets/heart+Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# One-hot encoding\n",
    "onehot_columns = [\"sex\", \"cp\", \"fbs\", \"restecg\", \"exang\", \"slope\", \"thal\"]\n",
    "\n",
    "# Numerical features\n",
    "other_columns = [\"age\", \"trestbps\", \"chol\", \"thalach\", \"oldpeak\", \"ca\"]\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"), onehot_columns),\n",
    "        (\"other\", \"passthrough\", other_columns),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# k-NN estimator\n",
    "knn_estimator = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"scaler\", StandardScaler()),  # Standardize features before k-NN\n",
    "        (\"knn\", KNeighborsClassifier()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid = {\n",
    "    \"knn__n_neighbors\": [1, 5, 10, 15, 20],\n",
    "    \"knn__weights\": [\"uniform\", \"distance\"],\n",
    "    \"knn__p\": [1, 2],\n",
    "}\n",
    "knn_gscv = GridSearchCV(knn_estimator, grid, cv=10, refit=True, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit/evaluate estimator\n",
    "knn_gscv.fit(X_tr, y_tr)\n",
    "\n",
    "# Collect results in a DataFrame\n",
    "knn_results = pd.DataFrame(\n",
    "    {\n",
    "        \"k\": knn_gscv.cv_results_[\"param_knn__n_neighbors\"],\n",
    "        \"p\": knn_gscv.cv_results_[\"param_knn__p\"],\n",
    "        \"weights\": knn_gscv.cv_results_[\"param_knn__weights\"],\n",
    "        \"mean_tr\": knn_gscv.cv_results_[\"mean_train_score\"],\n",
    "        \"mean_te\": knn_gscv.cv_results_[\"mean_test_score\"],\n",
    "        \"std_te\": knn_gscv.cv_results_[\"std_test_score\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Ten best combinations according to the mean \"test\" score\n",
    "# i.e. the mean score on the 10 validation folds\n",
    "knn_results.sort_values(by=\"mean_te\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k-NN baseline accuracy is around 66% ±8% (std) according to the validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report test score\n",
    "print(\"Test accuracy: {:.2f}%\".format(100 * knn_gscv.score(X_te, y_te)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise - Logistic regression\n",
    "---\n",
    "\n",
    "> **Exercise**: Same with a logistic regression\n",
    "> * Try both OvR and softmax\n",
    "> * tune C\n",
    ">\n",
    "> Which estimator would you use in practice? k-NN or logistic regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# Logistic regression estimator\n",
    "logreg_estimator = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\n",
    "            \"scaler\",\n",
    "            StandardScaler(),\n",
    "        ),  # due to standardization and solvers sensitive to rescaling\n",
    "        (\"logreg\", LogisticRegression()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Grid search with cross-validation\n",
    "Cs = np.logspace(-4, 4, num=20)\n",
    "grids = [\n",
    "    {\"logreg__multi_class\": [\"ovr\"], \"logreg__solver\": [\"liblinear\"], \"logreg__C\": Cs},\n",
    "    {\n",
    "        \"logreg__multi_class\": [\"multinomial\"],\n",
    "        \"logreg__solver\": [\"saga\"],\n",
    "        \"logreg__C\": Cs,\n",
    "    },\n",
    "]\n",
    "logreg_gscv = GridSearchCV(\n",
    "    logreg_estimator, grids, cv=10, refit=True, return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Filter convergence warnings\n",
    "warnings.simplefilter(\"ignore\", ConvergenceWarning)\n",
    "\n",
    "# Fit/evaluate estimator\n",
    "logreg_gscv.fit(X_tr, y_tr)\n",
    "\n",
    "# Collect results in a DataFrame\n",
    "logreg_results = pd.DataFrame(\n",
    "    {\n",
    "        \"strategy\": logreg_gscv.cv_results_[\"param_logreg__multi_class\"],\n",
    "        \"C\": logreg_gscv.cv_results_[\"param_logreg__C\"],\n",
    "        \"mean_tr\": logreg_gscv.cv_results_[\"mean_train_score\"],\n",
    "        \"mean_te\": logreg_gscv.cv_results_[\"mean_test_score\"],\n",
    "        \"std_te\": logreg_gscv.cv_results_[\"std_test_score\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Ten best combinations according to the mean test score\n",
    "logreg_results.sort_values(by=\"mean_te\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression accuracy is around 67% ± 7% (std) according to the validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report test score\n",
    "print(\"Test accuracy: {:.2f}%\".format(100 * logreg_gscv.score(X_te, y_te)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k-NN and logistic estimators are both better than the \"most-frequent\" baseline. However, after trying with different `random_state` seeds for the `train_test_split()` function, it's difficult to say that one is better than the other.\n",
    "\n",
    "It would be a good idea to track other metrics such as the precision, recall and F1 measures. For a reference of the different metrics implemented in Scikit-learn, see [Model evaluation guide](https://scikit-learn.org/stable/modules/model_evaluation.html#precision-recall-f-measure-metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
