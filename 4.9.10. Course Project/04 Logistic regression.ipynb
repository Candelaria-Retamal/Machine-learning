{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f78df942-b269-4e80-b150-ccb86679f0c8",
   "metadata": {},
   "source": [
    "# Unit 4: Applied Machine Learning 2\n",
    "## Task 4: Logistic regression\n",
    "###### Candelaria Retamal\n",
    "###### **22.06.2022**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b12e468-0151-40f4-81a8-98d38bd0fd84",
   "metadata": {},
   "source": [
    "#### 4.1. Train and evaluate a logistic regression\n",
    "Train and evaluate a logistic regression model (without any regularization penalty=\"none\" and without any hyperparameters tuning)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f35f44-198a-4699-9e75-7f08e405976c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> **Solution**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d71e1d1-c220-4e4b-9a18-4c6b9553f2bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (280, 1280) float32\n",
      "y: (280, 6) float32\n",
      "X: (280, 1280) float32\n",
      "y: (280, 6) float32\n",
      "X: (50, 1280) float32\n",
      "y: (50, 6) float32\n",
      "dtype: float64\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "with np.load(\"features_trainset.npz\") as npz_file:\n",
    "    X_tr = npz_file[\"data\"]\n",
    "    y_tr = npz_file[\"label\"]\n",
    "\n",
    "print(\"X:\", X_tr.shape, X_tr.dtype)\n",
    "print(\"y:\", y_tr.shape, y_tr.dtype)\n",
    "\n",
    "with np.load(\"features_testset.npz\") as npz_file:\n",
    "    X_te = npz_file[\"data\"]\n",
    "    y_te = npz_file[\"label\"]\n",
    "\n",
    "print(\"X:\", X_tr.shape, X_tr.dtype)\n",
    "print(\"y:\", y_tr.shape, y_tr.dtype)\n",
    "\n",
    "print(\"X:\", X_te.shape, X_te.dtype)\n",
    "print(\"y:\", y_te.shape, y_te.dtype)\n",
    "\n",
    "# Convert to float\n",
    "X_tr = X_tr.astype(np.float)\n",
    "X_te = X_te.astype(np.float)\n",
    "# Print the new data type\n",
    "print('dtype:', X_tr.dtype)\n",
    "print('dtype:', X_te.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a9a827e-a913-4901-9722-a17586d21945",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.940\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create the estimator\n",
    "logreg = LogisticRegression(penalty = \"none\")\n",
    "\n",
    "# Fit it to train data\n",
    "logreg.fit(X_tr, y_tr.argmax(axis=1))\n",
    "\n",
    "# Accuracy on test set\n",
    "accuracy = logreg.score(X_te, y_te.argmax(axis=1))\n",
    "print('Accuracy: {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05e0be1-f1b2-4107-99a2-14ca30f37d8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4.2. Get model coefficients\n",
    "Get the model coefficients using the coef_ attribute of your estimator and visualize them using a heatmap.\n",
    "* What are the largest 5 coefficients for each category (i.e. the indices of these coefficients)?\n",
    "* Are these results consistent with your observations during the data exploration in the last question of Task 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ee41b5-f0ed-4f9a-9689-03cc32834609",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> **Solution**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a208420b-6410-4e9a-81dd-84483252798e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coefficients = logreg.coef_\n",
    "cnt = 1\n",
    "for i in range (0,len(coefficients)):\n",
    "    idx=[]\n",
    "    idx = (coefficients[i]).argsort()[:5]\n",
    "    exec(f\"list_{cnt} = idx\")\n",
    "    cnt = cnt+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fe466c7-37a3-4faa-8244-3d483cc43018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          BIKE          |          CAR           |       MOTORCYCLE       |         OTHER          |         TRUCK          |          VAN           \n",
      "  ====================  |  ====================  |  ====================  |  ====================  |  ====================  |  ====================  \n",
      "                   580  |                  1022  |                   183  |                   257  |                   323  |                   679  \n",
      "                   870  |                   486  |                   466  |                   394  |                   473  |                   183  \n",
      "                   898  |                  1223  |                  1113  |                   419  |                  1029  |                     1  \n",
      "                   699  |                   389  |                   411  |                   861  |                   925  |                   440  \n",
      "                   466  |                  1179  |                   985  |                   346  |                   789  |                    49  \n",
      "        OLD BIKE        |        OLD CAR         |     OLD MOTORCYCLE     |       OLD OTHER        |       OLD TRUCK        |        OLD VAN         \n",
      "  ====================  |  ====================  |  ====================  |  ====================  |  ====================  |  ====================  \n",
      "                    54  |                   257  |                  1120  |                   411  |                  1022  |                  1022  \n",
      "                  1094  |                   660  |                  1122  |                   279  |                   714  |                  1104  \n",
      "                   183  |                   183  |                   898  |                   734  |                   580  |                  1113  \n",
      "                   801  |                   291  |                   505  |                   529  |                   335  |                   466  \n",
      "                   148  |                  1098  |                  1043  |                   580  |                  1051  |                   893  \n"
     ]
    }
   ],
   "source": [
    "from itertools import zip_longest\n",
    "\n",
    "\n",
    "header = ['BIKE', 'CAR', 'MOTORCYCLE',\"OTHER\",\"TRUCK\",\"VAN\"]\n",
    "\n",
    "#width = 14\n",
    "width = 20\n",
    "\n",
    "row = [\"  {:^{}}  \".format(item, width)\n",
    "              for item in header]\n",
    "\n",
    "print(\"|\".join(row))\n",
    "\n",
    "row = [\"  \" + \"=\"*width + \"  \"\n",
    "          for item in header]\n",
    "\n",
    "print(\"|\".join(row))\n",
    "\n",
    "\n",
    "for row in zip_longest(list_1, list_2, list_3, list_4,list_5,list_6):\n",
    "\n",
    "    # put empty string instead of `None`\n",
    "    row = [\"\" if item is None else item\n",
    "              for item in row]\n",
    "\n",
    "    # format every item to the same length\n",
    "    row = [\"  {:{}}  \".format(item, width)\n",
    "              for item in row]\n",
    "\n",
    "    # join all items in row using `|` and display row\n",
    "    print(\"|\".join(row))\n",
    "\n",
    "from itertools import zip_longest\n",
    "\n",
    "\n",
    "header = ['OLD BIKE', 'OLD CAR', 'OLD MOTORCYCLE',\"OLD OTHER\",\"OLD TRUCK\",\"OLD VAN\"]\n",
    "\n",
    "#width = 14\n",
    "width = 20\n",
    "\n",
    "row = [\"  {:^{}}  \".format(item, width)\n",
    "              for item in header]\n",
    "\n",
    "print(\"|\".join(row))\n",
    "\n",
    "row = [\"  \" + \"=\"*width + \"  \"\n",
    "          for item in header]\n",
    "\n",
    "print(\"|\".join(row))\n",
    "\n",
    "old_1 = [54, 1094, 183, 801, 148]\n",
    "old_2 = [257, 660, 183, 291, 1098]\n",
    "old_3 = [1120, 1122, 898, 505, 1043]\n",
    "old_4 = [411, 279, 734, 529, 580]\n",
    "old_5 = [1022, 714, 580, 335, 1051]\n",
    "old_6 = [1022, 1104, 1113, 466, 893]\n",
    "\n",
    "for row in zip_longest(old_1, old_2, old_3, old_4,old_5,old_6):\n",
    "\n",
    "    # put empty string instead of `None`\n",
    "    row = [\"\" if item is None else item\n",
    "              for item in row]\n",
    "\n",
    "    # format every item to the same length\n",
    "    row = [\"  {:{}}  \".format(item, width)\n",
    "              for item in row]\n",
    "\n",
    "    # join all items in row using `|` and display row\n",
    "    print(\"|\".join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "480af10c-6678-4fc7-8f2b-06b1c394f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to illustrate the intersection\n",
    "def intersection(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    return lst3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a25cfbd-877d-4506-81d9-82a5d71f5c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Bikes and all the rest\n",
    "print(intersection(list_1, old_1))\n",
    "print(intersection(list_2, old_2))\n",
    "print(intersection(list_3, old_3))\n",
    "print(intersection(list_4, old_4))\n",
    "print(intersection(list_5, old_5))\n",
    "print(intersection(list_6, old_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37017b48-638e-41ce-a1c4-d61dadfe2cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[466]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Bikes and all the rest\n",
    "print(intersection(list_1, list_2))\n",
    "print(intersection(list_1, list_3))\n",
    "print(intersection(list_1, list_4))\n",
    "print(intersection(list_1, list_5))\n",
    "print(intersection(list_1, list_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3211f307-491f-4056-9254-32d315d11f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Cars and all except bikes\n",
    "print(intersection(list_2, list_3))\n",
    "print(intersection(list_2, list_4))\n",
    "print(intersection(list_2, list_5))\n",
    "print(intersection(list_2, list_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3664f91a-1576-4652-ab79-894b84af8d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[183]\n"
     ]
    }
   ],
   "source": [
    "# Motorcycle\n",
    "print(intersection(list_3, list_4))\n",
    "print(intersection(list_3, list_5))\n",
    "print(intersection(list_3, list_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57895336-fab4-4b1a-bd35-03b6167cac57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Other\n",
    "print(intersection(list_4, list_5))\n",
    "print(intersection(list_4, list_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1468360-b5a8-494e-9ae4-5d3d63d2eb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Truck\n",
    "print(intersection(list_5, list_6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8fde35-7a35-4072-a81b-fb4e34057683",
   "metadata": {},
   "source": [
    "#### 4.3. l2 regularization and strength parameters\n",
    "Set an “l2” regularization and tune the regularization strength parameter of the model with cross-validated grid-search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ab6d66-bf9c-4b24-8a62-1b03965e3414",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> **Solution**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1ef7c86-0016-47b9-a4b9-75a030603a13",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.980\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create pipeline\n",
    "pipe = Pipeline(\n",
    "    [(\"logreg\", LogisticRegression(penalty = \"l2\",multi_class=\"ovr\", solver=\"liblinear\")),\n",
    "    ]\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Create cross-validation object\n",
    "grid = {\"logreg__C\": np.logspace(-5, 5, num=10)}\n",
    "grid_cv = GridSearchCV(pipe, grid, cv=5, return_train_score=True)\n",
    "# Fit estimator\n",
    "grid_cv.fit(X_tr, y_tr.argmax(axis=1))\n",
    "\n",
    "# Accuracy on test set\n",
    "accuracy = grid_cv.score(X_te, y_te.argmax(axis=1))\n",
    "print('Accuracy: {:.3f}'.format(accuracy))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Collect results in a DataFrame\n",
    "cv_results = pd.DataFrame(grid_cv.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba7e9c7-6dcc-48ba-b347-ea3e14a33035",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4.4. Report the result of cross-validated grid-search\n",
    "Report the result of cross-validated grid-search as a dataframe and interpret the result. In particular, briefly explain what are the mean_train_score, mean_test_score, std_train_score and std_test_score:\n",
    "* How are they obtained?\n",
    "* What do they measure?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450c1448-8764-4c02-8474-d11031c0d0d3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> **Solution**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fc3fcca-b2b7-402e-be75-5623b0a768c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>param_logreg__C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.896429</td>\n",
       "      <td>0.026245</td>\n",
       "      <td>0.997321</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.021544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.025254</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.278256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.889286</td>\n",
       "      <td>0.026245</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.593814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.889286</td>\n",
       "      <td>0.026245</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>599.48425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.889286</td>\n",
       "      <td>0.026245</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7742.636827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.889286</td>\n",
       "      <td>0.026245</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.029014</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.415888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.846429</td>\n",
       "      <td>0.046015</td>\n",
       "      <td>0.927679</td>\n",
       "      <td>0.005923</td>\n",
       "      <td>0.001668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.782143</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.783036</td>\n",
       "      <td>0.006056</td>\n",
       "      <td>0.000129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.024223</td>\n",
       "      <td>0.698214</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_score  std_test_score  mean_train_score  std_train_score  \\\n",
       "3         0.896429        0.026245          0.997321         0.002187   \n",
       "4         0.892857        0.025254          1.000000         0.000000   \n",
       "5         0.889286        0.026245          1.000000         0.000000   \n",
       "7         0.889286        0.026245          1.000000         0.000000   \n",
       "8         0.889286        0.026245          1.000000         0.000000   \n",
       "9         0.889286        0.026245          1.000000         0.000000   \n",
       "6         0.885714        0.029014          1.000000         0.000000   \n",
       "2         0.846429        0.046015          0.927679         0.005923   \n",
       "1         0.782143        0.020825          0.783036         0.006056   \n",
       "0         0.685714        0.024223          0.698214         0.012500   \n",
       "\n",
       "  param_logreg__C  \n",
       "3        0.021544  \n",
       "4        0.278256  \n",
       "5        3.593814  \n",
       "7       599.48425  \n",
       "8     7742.636827  \n",
       "9        100000.0  \n",
       "6       46.415888  \n",
       "2        0.001668  \n",
       "1        0.000129  \n",
       "0         0.00001  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a few interesting columns\n",
    "cols = [\n",
    "    \"mean_test_score\",\n",
    "    \"std_test_score\",\n",
    "    \"mean_train_score\",\n",
    "    \"std_train_score\",\n",
    "    \"param_logreg__C\",\n",
    "]\n",
    "cv_results[cols].sort_values(\"mean_test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169b7886-265a-42bd-ba78-70b077f706a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4.5. Train and validation curves\n",
    "Plot the training and validation curves:\n",
    "* Compare the accuracies to the non-regularized model above.\n",
    "* Do the curves indicate overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf299d1-dec2-4070-a3a0-50697c14affe",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> **Solution**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174eea76-85f5-4b6d-81b8-eff2bebbb0c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training/validation accuracy curves\n",
    "plt.semilogx(cv_results[\"param_logreg__C\"], cv_results[\"mean_train_score\"], label='training accuracy')\n",
    "plt.semilogx(cv_results[\"param_logreg__C\"], cv_results[\"mean_test_score\"],  label='validation accuracy')\n",
    "plt.xlabel('Regularization strength (C)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Evolution of training/validation accuracy with $C$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d18acf-2691-47be-b3d9-8733eec4745e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4.6. Classification report and confusion matrix \n",
    "Provide a classification report and visualize the confusion matrix of the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f991d27-cf8c-487e-b6c6-0c78bf4b5126",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> **Solution**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb4c51db-1822-4c2a-b919-3e2fb5fc974c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       0.92      1.00      0.96        11\n",
      "           2       1.00      1.00      1.00         9\n",
      "           3       1.00      1.00      1.00         6\n",
      "           4       1.00      1.00      1.00         7\n",
      "           5       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.98        50\n",
      "   macro avg       0.99      0.97      0.97        50\n",
      "weighted avg       0.98      0.98      0.98        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "# Classification report\n",
    "y_te_preds = grid_cv.predict(X_te)\n",
    "print(classification_report(y_true=y_te.argmax(axis=1), y_pred=y_te_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "900c5579-1271-4f0e-9e35-ff1dc6e80635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred: bike</th>\n",
       "      <th>pred: car</th>\n",
       "      <th>pred: motorcycle</th>\n",
       "      <th>pred: other</th>\n",
       "      <th>pred: truck</th>\n",
       "      <th>pred: van</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true: bike</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true: car</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true: motorcycle</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true: other</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true: truck</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true: van</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pred: bike  pred: car  pred: motorcycle  pred: other  \\\n",
       "true: bike                12          0                 0            0   \n",
       "true: car                  0         11                 0            0   \n",
       "true: motorcycle           0          0                 9            0   \n",
       "true: other                0          0                 0            6   \n",
       "true: truck                0          0                 0            0   \n",
       "true: van                  0          1                 0            0   \n",
       "\n",
       "                  pred: truck  pred: van  \n",
       "true: bike                  0          0  \n",
       "true: car                   0          0  \n",
       "true: motorcycle            0          0  \n",
       "true: other                 0          0  \n",
       "true: truck                 7          0  \n",
       "true: van                   0          4  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Confusion matrix\n",
    "matrix = confusion_matrix(y_true=y_te.argmax(axis=1), y_pred=y_te_preds)\n",
    "\n",
    "# Confusion matrix as a DataFrame\n",
    "matrix_df = pd.DataFrame(\n",
    "    matrix,\n",
    "    columns=[\"pred: bike\", \"pred: car\", \"pred: motorcycle\", \"pred: other\", \"pred: truck\", \"pred: van\"],\n",
    "    index=[\"true: bike\", \"true: car\",\"true: motorcycle\", \"true: other\", \"true: truck\", \"true: van\"],\n",
    ")\n",
    "\n",
    "matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fb1d70-64cd-4c8a-8c95-17c51fc1577e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:adsml] *",
   "language": "python",
   "name": "conda-env-adsml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
