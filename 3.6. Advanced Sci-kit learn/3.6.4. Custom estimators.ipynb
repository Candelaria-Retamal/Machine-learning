{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc16d272-74b9-4710-ac22-5a27a0c53011",
   "metadata": {},
   "source": [
    "#### Custom estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a8d35b-f864-438a-a526-9364659b3d90",
   "metadata": {},
   "source": [
    "In the last unit, we saw how to define our own transformers. In this unit, we will see how to implement custom estimators with the scenario of outliers removal.\n",
    "\n",
    "#### Use case - outliers removal\n",
    "Let’s start by loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "651f8ad3-277f-4750-9205-394903855ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>...</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>484</td>\n",
       "      <td>528275070</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8795</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>236000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2586</td>\n",
       "      <td>535305120</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10170</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2289</td>\n",
       "      <td>923228250</td>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142</td>\n",
       "      <td>535152150</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>10552</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>165500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2042</td>\n",
       "      <td>903475060</td>\n",
       "      <td>190</td>\n",
       "      <td>RM</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10120</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Bnk</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n",
       "0    484  528275070           60        RL           NaN      8795   Pave   \n",
       "1   2586  535305120           20        RL          75.0     10170   Pave   \n",
       "2   2289  923228250          160        RM          21.0      2001   Pave   \n",
       "3    142  535152150           20        RL          70.0     10552   Pave   \n",
       "4   2042  903475060          190        RM          60.0     10120   Pave   \n",
       "\n",
       "  Alley Lot Shape Land Contour  ... Pool Area Pool QC  Fence Misc Feature  \\\n",
       "0   NaN       IR1          Lvl  ...         0     NaN    NaN          NaN   \n",
       "1   NaN       Reg          Lvl  ...         0     NaN    NaN          NaN   \n",
       "2   NaN       Reg          Lvl  ...         0     NaN    NaN          NaN   \n",
       "3   NaN       IR1          Lvl  ...         0     NaN    NaN          NaN   \n",
       "4   NaN       IR1          Bnk  ...         0     NaN  MnPrv          NaN   \n",
       "\n",
       "  Misc Val Mo Sold Yr Sold Sale Type  Sale Condition  SalePrice  \n",
       "0        0       4    2009       WD           Normal     236000  \n",
       "1        0       6    2006       WD           Normal     155000  \n",
       "2        0       1    2007       WD           Normal      75000  \n",
       "3        0       4    2010       WD           Normal     165500  \n",
       "4        0       1    2007       WD           Normal     122000  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_df = pd.read_csv(\"c3_house-prices.csv\")\n",
    "data_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a826ebd2-40d6-4c9b-b0f7-3ca8be5c1196",
   "metadata": {},
   "source": [
    "We learned about skewed distributions in the last subject and saw how log-transforms can help in such cases. However, it’s still possible that some values remain far from the mean after the transformation.\n",
    "\n",
    "For instance, let’s plot the z-scores distribution of the Lot Area variable before and after the log-transform. This time, we use the zscore() function from the scipy.stats module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "936076b6-a396-4d2b-a052-1047f6ba3699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "\n",
    "# Check for outliers in the continuous features\n",
    "c = \"Lot Area\"\n",
    "x = data_df[c].dropna()\n",
    "\n",
    "# Plot histograms\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(10, 3))\n",
    "ax1.hist(zscore(x), bins=50)\n",
    "ax2.hist(zscore(np.log1p(x)), bins=50)\n",
    "ax1.set_title(c)\n",
    "ax2.set_title(\"log({})\".format(c))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b30769-a822-4d4e-a9b2-7fa1289f1e12",
   "metadata": {},
   "source": [
    "We can see that the transformation helps, but there are still many values with a z-score above +3 or below -3. We could simply remove them with Pandas before applying our ML models in Scikit-learn. However, let’s see how to encapsulate this preprocessing step into a Scikit-learn object.\n",
    "\n",
    "The Lot Area isn’t the only variable with a skewed distribution in this dataset. In the following code, we list them and create the train and test sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e31dcb74-0fa6-4fa3-81c5-626d99caab47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Total Bsmt SF</th>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <th>Garage Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>20896</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2077.0</td>\n",
       "      <td>2097</td>\n",
       "      <td>1134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>8930</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1902</td>\n",
       "      <td>539.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2167</th>\n",
       "      <td>3811</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1594.0</td>\n",
       "      <td>1646</td>\n",
       "      <td>482.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>11200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1298.0</td>\n",
       "      <td>1298</td>\n",
       "      <td>403.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>31250</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600</td>\n",
       "      <td>270.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Lot Area  Lot Frontage  Total Bsmt SF  Gr Liv Area  Garage Area\n",
       "339      20896          49.0         2077.0         2097       1134.0\n",
       "1557      8930          68.0            0.0         1902        539.0\n",
       "2167      3811          44.0         1594.0         1646        482.0\n",
       "706      11200           NaN         1298.0         1298        403.0\n",
       "2396     31250         125.0            0.0         1600        270.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create X, y\n",
    "X = data_df.drop(\"SalePrice\", axis=1)\n",
    "y = np.log10(data_df.SalePrice)\n",
    "\n",
    "# Split into train/test sets\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Continuous variables to check\n",
    "to_check = [\"Lot Area\", \"Lot Frontage\", \"Total Bsmt SF\", \"Gr Liv Area\", \"Garage Area\"]\n",
    "X_tr[to_check].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f477e2d-26b0-40a9-9903-8812668bd258",
   "metadata": {},
   "source": [
    "Note that we still have missing values in the data. In this unit, we ignore them during the outliers removal part and will then see later in this unit how to replace them using a SimpleImputer transformer object.\n",
    "\n",
    "#### ClassifierMixin object\n",
    "In the last unit, we defined our own transformers by creating a subclass of the BaseEstimator and TransformerMixin. Similarly, we can define custom estimators by creating a subclass of BaseEstimator and\n",
    "\n",
    "RegressorMixin for regression tasks\n",
    "ClassifierMixin for classification ones\n",
    "Let’s see how to create a ZScoresOutlierClassifier class that takes a set of column names to check for outliers and a removal threshold. This custom estimator will predict whether a point is an outlier or not - since this is a classification task, we need to extend ClassifierMixin.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36264cc5-c970-46c3-8a95-4aa7fcf2b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "# Custom outliers detector base on z-scores\n",
    "# Adapted from https://github.com/scikit-learn/scikit-learn/issues/9630#issuecomment-325202441\n",
    "class ZScoresOutlierClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, columns, threshold=3):\n",
    "        self.columns = columns\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def fit(self, X_df, y):\n",
    "        # Check that X_df is a DataFrame\n",
    "        assert type(X_df) == pd.DataFrame\n",
    "\n",
    "        # Compute train mean/std\n",
    "        self.train_mean_ = X_df[self.columns].mean()\n",
    "        self.train_std_ = X_df[self.columns].std()\n",
    "\n",
    "        # Return estimator\n",
    "        return self\n",
    "\n",
    "    def predict(self, X_df):\n",
    "        # Check that X_df is a DataFrame\n",
    "        assert type(X_df) == pd.DataFrame\n",
    "\n",
    "        # Apply threshold\n",
    "        z_scores = (X_df[self.columns] - self.train_mean_) / (self.train_std_)\n",
    "        below_threshold = np.abs(z_scores.fillna(0)) <= self.threshold\n",
    "\n",
    "        # Find inliners\n",
    "        mask = below_threshold.all(axis=1)\n",
    "\n",
    "        # Return predictions: +1 for inliners, -1 for outliers\n",
    "        return mask.replace({True: 1, False: -1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14404c43-fab8-4690-a196-1940601304ec",
   "metadata": {},
   "source": [
    "In this code, we define two functions: fit() and predict().\n",
    "\n",
    "The fit function computes the mean and standard deviation of each column of the train DataFrame and stores them in the train_mean_ and train_std_ variables. The “predict” part computes the z-scores using simple Pandas code and checks that the data points are below the defined threshold.\n",
    "\n",
    "Note the Pandas all(axis=1) call - a point that isn’t an outlier should have all its z-scores below the threshold. Finally, we return 1 for normal points and -1 for outliers: this is the standard encoding for outlier detector objects from Scikit-learn.\n",
    "\n",
    "Let’s test our custom classifier on the training data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "217864d4-e965-457d-aac2-a2f8ce29a713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339    -1\n",
       "1557    1\n",
       "2167    1\n",
       "706     1\n",
       "2396    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers_clf = ZScoresOutlierClassifier(to_check)\n",
    "outliers_clf.fit(X_tr, y_tr)\n",
    "outliers_clf.predict(X_tr).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2b86d9-a6df-4729-9939-c30abe48efb5",
   "metadata": {},
   "source": [
    "As we can see, the first point is labeled as an outlier and shouldn’t be used to train the model.\n",
    "\n",
    "Challenge: We didn’t check for outliers in the output variable - can you adapt the code to also handle extreme values in the target?\n",
    "\n",
    "#### RegressorMixin object\n",
    "Now that we have a custom outlier classifier, let’s see how to use it to improve our predictions. Remember: outliers hurt the performance of our models because of the RSS-based cost functions which have bad statistical properties i.e. they don’t handle well statistically extreme values.\n",
    "\n",
    "Let’s define a WithoutOutliersRegressor object that first removes the outliers from the training data before fitting the estimator.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed17b92a-41ad-47f9-acce-95f5420d7c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import RegressorMixin, clone\n",
    "\n",
    "# Custom regressor with an embedded outliers detector\n",
    "# Adapted from https://github.com/scikit-learn/scikit-learn/issues/9630#issuecomment-325202441\n",
    "class WithoutOutliersRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, outlier_detector, regressor):\n",
    "        self.outlier_detector = outlier_detector\n",
    "        self.regressor = regressor\n",
    "\n",
    "    def fit(self, X, y, verbose=False):\n",
    "        # Fit outliers detector, use it on X\n",
    "        self.outlier_detector_ = clone(self.outlier_detector).fit(X, y)\n",
    "        outliers = self.outlier_detector_.predict(X) == -1\n",
    "\n",
    "        # Print the number of outliers detected\n",
    "        if verbose:\n",
    "            print(\n",
    "                \"Outliers detected: {} ({:.1f}%)\".format(\n",
    "                    outliers.sum(), 100 * outliers.mean()\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Fit regressor without the outliers\n",
    "        self.regressor_ = clone(self.regressor).fit(X[~outliers], y[~outliers])\n",
    "\n",
    "        # Return the estimator\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Make predictions with the regressor (fitted without the outliers)\n",
    "        return self.regressor_.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1e978b-4e0b-4aa5-b35b-63e1f9c9a542",
   "metadata": {},
   "source": [
    "Again, we need to define the fit() and predict() functions.\n",
    "\n",
    "In the fit part, we fit our outlier detector to the training data, create an outliers mask and use it to exclude outliers from our model fit() call. In the “predict” part, we simply use our fitted regressor object to make new predictions for all data points i.e. including potential outliers.\n",
    "\n",
    "So far in this course, we always saw examples where the current state of our estimators was clear ex. is it fitted, on what data are the coefficients computed and so on. However, in this implementation, we are working with an outlier detector and a regressor that are created outside our custom estimator, and we modify them inside it by calling the .fit() method.\n",
    "\n",
    "To avoid any confusion, we clone the estimators with the clone() function from Scikit-learn - that way, we are sure to leave the original objects unmodified. This issue is very similar to what can happen with Pandas inplace=True operations. If you’re curious about this, you can take a look at this example which illustrate the issue.\n",
    "\n",
    "#### Complete pipeline\n",
    "Let’s use our new estimator in a complete pipeline. First, we need to fill missing values and encode non-numerical variables. This time, we will use the SimpleImputer object from Scikit-learn to handle missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46d9878f-a16a-466f-a90a-5e762187507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# One-hot encoding for non-numerical columns\n",
    "onehot_columns = X.select_dtypes(exclude=np.number).columns\n",
    "onehot_transformer = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4883a8c7-22cc-49b5-ba51-385bdc013506",
   "metadata": {},
   "source": [
    "By setting its strategy parameter to most_frequent, the imputer simply replaces missing values with the most frequent value found in the column. Other possible strategies are mean, median and constant. You can always refer to the documentation if you’re unsure about the different options.\n",
    "\n",
    "Let’s also define the transformations for the numerical columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99826f6b-03f4-428a-83fb-f046930ebf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Basic transformations for the others\n",
    "other_columns = X.columns.difference(onehot_columns)\n",
    "other_transformer = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"log\", FunctionTransformer(np.log1p)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d05cb97-f2b0-4249-a922-4fabde5f66b2",
   "metadata": {},
   "source": [
    "Again, we perform minimal preprocessing steps. We first impute missing values, apply the log-transform and standardize the results.\n",
    "\n",
    "Let’s collect the preprocessing steps into a final ColumnTransformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ddee6fc-311d-4a83-b68c-e781d1856663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Create preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"onehot\", onehot_transformer, onehot_columns),\n",
    "        (\"other\", other_transformer, other_columns),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1b7e96-892b-449c-9ffa-9040345c6a7b",
   "metadata": {},
   "source": [
    "Finally, let’s create our WithoutOutliersRegressor custom estimator. We simply need to pass the outlier detector and the regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6779febb-3f28-4809-a9f7-cfd18a401969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Define pipeline\n",
    "model = WithoutOutliersRegressor(\n",
    "    outlier_detector=ZScoresOutlierClassifier(to_check, threshold=3),\n",
    "    regressor=Pipeline([(\"preprocessor\", preprocessor), (\"ridge\", Ridge())]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42d4e4f-a612-4318-95db-ab7a040c074a",
   "metadata": {},
   "source": [
    "It’s important to note that our ZScoresOutlierClassifier works on the untransformed DataFrame - our preprocessor is only applied before the Ridge model! For this reason, the detector is working on the original variables and not the log-transformed ones.\n",
    "\n",
    "To apply the outliers detector on the log-transformed variables, we cannot simply encapsulate our detector into a ColumnTransformer that applies the log-transform to the columns listed in to_check. The reason is simple: as we saw in the last units, column transformer objects produce Numpy arrays. However, our outliers detector works on DataFrames!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eef4cc5-d914-487c-85d2-9f8694ead8ce",
   "metadata": {},
   "source": [
    "#### Final evaluation\n",
    "Let’s see how our fully-encapsulated model performs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ab211d1-9821-4809-91f6-ee7be9e3d608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers detected: 38 (3.1%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WithoutOutliersRegressor(outlier_detector=ZScoresOutlierClassifier(columns=['Lot '\n",
       "                                                                            'Area',\n",
       "                                                                            'Lot '\n",
       "                                                                            'Frontage',\n",
       "                                                                            'Total '\n",
       "                                                                            'Bsmt '\n",
       "                                                                            'SF',\n",
       "                                                                            'Gr '\n",
       "                                                                            'Liv '\n",
       "                                                                            'Area',\n",
       "                                                                            'Garage '\n",
       "                                                                            'Area']),\n",
       "                         regressor=Pipeline(steps=[('preprocessor',\n",
       "                                                    ColumnTransformer(transformers=[('onehot',\n",
       "                                                                                     Pipeline(steps=[('imputer',\n",
       "                                                                                                      SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                                     ('encoder',\n",
       "                                                                                                      OneHotEncoder(handle_unknown='ig...\n",
       "       'Garage Area', 'Garage Cars', 'Garage Yr Blt', 'Gr Liv Area',\n",
       "       'Half Bath', 'Kitchen AbvGr', 'Lot Area', 'Lot Frontage',\n",
       "       'Low Qual Fin SF', 'MS SubClass', 'Mas Vnr Area', 'Misc Val', 'Mo Sold',\n",
       "       'Open Porch SF', 'Order', 'Overall Cond', 'Overall Qual', 'PID',\n",
       "       'Pool Area', 'Screen Porch', 'TotRms AbvGrd', 'Total Bsmt SF',\n",
       "       'Wood Deck SF', 'Year Built', 'Year Remod/Add', 'Yr Sold'],\n",
       "      dtype='object'))])),\n",
       "                                                   ('ridge', Ridge())]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "\n",
    "model.fit(X_tr, y_tr, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeea303-38e0-47de-bc33-41ef4a937524",
   "metadata": {},
   "source": [
    "The outlier detector labeled around 3% of the entries as outliers. Those training points won’t be used to fit the model.\n",
    "\n",
    "Let’s evaluate it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dc98a0b-54f5-45e6-a195-6c40a49516fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 14,215.87$\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "\n",
    "# Evaluate predictions\n",
    "y_pred = model.predict(X_te)\n",
    "print(\"MAE: {:,.2f}$\".format(MAE(10 ** y_te, 10 ** y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f28319c-b7b8-4326-ad06-f8c1ee162b85",
   "metadata": {},
   "source": [
    "This time, we get an MAE score around 14 thousand dollars which is similar to what we obtained in the previous units.\n",
    "\n",
    "The advantage of our pipeline is that we can easily switch to other outlier detection methods. It’s not part of the course to know how the different detectors work, but it’s important to know that Scikit-learn implements many advanced techniques that can be used out-of-the-box once we are familiar with the transformers and estimators API.\n",
    "\n",
    "The library also does a great job at documenting the different approaches. If you google sklearn outlier detection, you should get this page which documents them in the top results.\n",
    "\n",
    "For instance, let’s try with the IsolationForest detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cc3b456-2d8a-43e2-b8ae-c30949720572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers detected: 5 (0.4%)\n",
      "MAE: 14,480.59$\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Try with Isolation forests\n",
    "model2 = WithoutOutliersRegressor(\n",
    "    outlier_detector=make_pipeline(preprocessor, IsolationForest(random_state=0)),\n",
    "    regressor=Pipeline([(\"preprocessor\", preprocessor), (\"ridge\", Ridge())]),\n",
    ")\n",
    "model2.fit(X_tr, y_tr, verbose=True)\n",
    "\n",
    "# Evaluate predictions\n",
    "y_pred = model2.predict(X_te)\n",
    "print(\"MAE: {:,.2f}$\".format(MAE(10 ** y_te, 10 ** y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db35475-4d92-4e8c-a3ec-136068f0445f",
   "metadata": {},
   "source": [
    "This time, we add our preprocessor before the IsolationForest using the make_pipeline() function to quickly create a Pipeline without having to name each step.\n",
    "\n",
    "As we can see, the isolation forest labels 10% of the data points as outliers and we get a slightly larger MAE score.\n",
    "\n",
    "#### Summary\n",
    "In this unit, we saw how to create custom estimators with the example of outliers removal. Custom estimators can be particularly useful if we need to encapsulate tools from other libraries into our Scikit-learn workflow. For instance, encapsulate ML methods from NLTK, TensorFlow or even our own algorithms.\n",
    "\n",
    "In the next unit, we will discuss advanced transformations that can improve the performance of our models. This will end our tour of the Scikit-learn library and machine learning workflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:adsml] *",
   "language": "python",
   "name": "conda-env-adsml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
