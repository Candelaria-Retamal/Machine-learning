{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spirals dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise - Load and plot data\n",
    "---\n",
    "\n",
    "> **Exercise**: Load the data and plot the `x1` and `x2` variables. Use one color for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load dataset\n",
    "data_df = pd.read_csv(\"c4_spirals.csv\")\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# Create X/y arrays\n",
    "X = scale(data_df.drop(\"y\", axis=1).values)  # Rescale input data\n",
    "y = data_df.y.values\n",
    "\n",
    "print(\"X:\", X.shape, X.dtype)\n",
    "print(\"y:\", y.shape, y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_aspect(\"equal\", adjustable=\"box\")  # same scale for x- and y-axis\n",
    "\n",
    "# Plot data\n",
    "class1_idx = y == 1  # Points from class 1\n",
    "ax.scatter(X[:, 0][class1_idx], X[:, 1][class1_idx], label=\"class 1\", color=\"C3\", s=6)\n",
    "ax.scatter(X[:, 0][~class1_idx], X[:, 1][~class1_idx], label=\"class 0\", color=\"C0\", s=6)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise - Compare classifiers\n",
    "---\n",
    "\n",
    "> **Exercise**: Fit the following classifiers and plot them using the `decision_surface()` function from the course.\n",
    "> * Logistic regression\n",
    "> * SVM with linear kernel\n",
    "> * *k*-NN\n",
    "> * Decision tree\n",
    "> * Random forest\n",
    "> * SVM with RBF kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function from course\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Helper function\n",
    "def decision_surface(ax, x1, x2, y, estimator):\n",
    "    # Same scale for x- and y-axis\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "    # Plot data points\n",
    "    class1_idx = y == 1\n",
    "    plt.scatter(x1[class1_idx], x2[class1_idx], color=\"C3\", label=\"class 1\", s=6)\n",
    "    plt.scatter(x1[~class1_idx], x2[~class1_idx], color=\"C0\", label=\"class 0\", s=6)\n",
    "\n",
    "    # Create a grid of values\n",
    "    xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
    "    x_values = np.linspace(*xlim, num=500)\n",
    "    y_values = np.linspace(*ylim, num=500)\n",
    "    xx, yy = np.meshgrid(x_values, y_values)\n",
    "    grid_points = np.c_[xx.flatten(), yy.flatten()]\n",
    "\n",
    "    # Compute predictions\n",
    "    preds = estimator.predict(grid_points)\n",
    "    zz = preds.reshape(xx.shape)\n",
    "\n",
    "    # Draw decision boundary\n",
    "    plt.contour(xx, yy, zz, levels=[0.5], colors=\"gray\")\n",
    "\n",
    "    # Plot decision surface with level curves\n",
    "    plt.contourf(xx, yy, zz, alpha=0.1, cmap=plt.cm.coolwarm)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic regression\n",
    "logreg = LogisticRegression(solver=\"liblinear\", random_state=0)\n",
    "logreg.fit(X, y)\n",
    "fig, ax = plt.subplots()\n",
    "decision_surface(ax, X[:, 0], X[:, 1], y, logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear SVM\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# SVM with linear kernel\n",
    "linear_svc = LinearSVC(random_state=0)\n",
    "linear_svc.fit(X, y)\n",
    "fig, ax = plt.subplots()\n",
    "decision_surface(ax, X[:, 0], X[:, 1], y, linear_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-nearest neighbors\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# k-NN\n",
    "knn = KNeighborsClassifier(n_neighbors=50)\n",
    "knn.fit(X, y)\n",
    "fig, ax = plt.subplots()\n",
    "decision_surface(ax, X[:, 0], X[:, 1], y, knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Decision tree\n",
    "dt = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "dt.fit(X, y)\n",
    "fig, ax = plt.subplots()\n",
    "decision_surface(ax, X[:, 0], X[:, 1], y, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random forest\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=0)\n",
    "rf.fit(X, y)\n",
    "fig, ax = plt.subplots()\n",
    "decision_surface(ax, X[:, 0], X[:, 1], y, rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RBF SVM\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Random forest\n",
    "rbf_svc = SVC(kernel=\"rbf\", C=10, gamma=1, random_state=0)\n",
    "rbf_svc.fit(X, y)\n",
    "fig, ax = plt.subplots()\n",
    "decision_surface(ax, X[:, 0], X[:, 1], y, rbf_svc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
