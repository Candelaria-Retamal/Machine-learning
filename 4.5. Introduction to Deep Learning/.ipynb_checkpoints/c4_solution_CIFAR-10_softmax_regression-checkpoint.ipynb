{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOLUTION NOTEBOOK\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 softmax regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution - Load and preprocess data\n",
    "---\n",
    "\n",
    "> **Exercise**: Load the data from the `cifar10-6k.npz` file. Split it into train/validation/test sets with respectively 5,000/500/500 images. Standardize them. Define a `get_batches(X, y, batch_size)` function to generate X/y batches of size `batch_size` using a Python generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "with np.load(os.path.join(\"c4_cifar10-6k.npz\"), allow_pickle=False) as npz_file:\n",
    "    cifar10 = dict(npz_file.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    # Convert uint8 pixel values to float\n",
    "    cifar10[\"data\"].astype(np.float32),\n",
    "    cifar10[\"labels\"],\n",
    "    test_size=1000,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "# Split test into validation/test sets\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "    X_test, y_test, test_size=500, random_state=0\n",
    ")\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get batches of data\n",
    "def get_batches(X, y, batch_size):\n",
    "    # Enumerate indexes by steps of batch_size\n",
    "    # i: 0, b, 2b, 3b, 4b, .. where b is the batch size\n",
    "    for i in range(0, len(y), batch_size):\n",
    "        # \"yield\" data between index i and i+b (not included)\n",
    "        yield X[i : i + batch_size], y[i : i + batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution - Build and train model\n",
    "---\n",
    "\n",
    "> **Exercise:** Create a softmax regression network for the CIFAR-10 images. Initialize the parameters and the optimizer first. Use the graph mode and the `tf.function` decorator to define the different computations needed (logits, loss, accuracy, training). Train your model then using the batch generator.\n",
    "\n",
    "**Hint**: Test different learning rates for the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the logits\n",
    "@tf.function\n",
    "def compute_logits(x, W, b):\n",
    "    logits = tf.add(tf.matmul(x, W), b)\n",
    "    return logits\n",
    "\n",
    "\n",
    "# Compute the loss\n",
    "@tf.function\n",
    "def compute_loss(y, logits):\n",
    "    ce = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    mean_ce = tf.reduce_mean(ce)\n",
    "    return mean_ce\n",
    "\n",
    "\n",
    "# Compute the accuracy\n",
    "@tf.function\n",
    "def compute_accuracy(y, logits):\n",
    "    predictions = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
    "    is_correct = tf.equal(y, predictions)\n",
    "    acc = tf.reduce_mean(tf.cast(is_correct, dtype=tf.float32))\n",
    "    return acc\n",
    "\n",
    "\n",
    "# Train the model (optimization procedure)\n",
    "@tf.function\n",
    "def train(x, y, W, b):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = compute_logits(x, W, b)\n",
    "        loss = compute_loss(y, logits)\n",
    "    optimizer.minimize(loss=loss, var_list=[W, b], tape=tape)\n",
    "    return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Accuracy scores after each batch\n",
    "train_acc_values = []\n",
    "valid_acc_values = []\n",
    "\n",
    "\n",
    "# Initialize the network parameters to zero\n",
    "W = tf.Variable(initial_value=tf.zeros(shape=[3072, 10]))\n",
    "b = tf.Variable(initial_value=tf.zeros(shape=[10]))\n",
    "\n",
    "\n",
    "# Get batches of data\n",
    "for X_batch, y_batch in get_batches(X_train, y_train, 64):\n",
    "    # Run training\n",
    "    train_logits, _ = train(X_batch, y_batch, W, b)\n",
    "\n",
    "    # Evaluate training accuracy\n",
    "    train_acc = compute_accuracy(y_batch, train_logits)\n",
    "    train_acc_values.append(train_acc)\n",
    "\n",
    "    # Evaluate validation accuracy\n",
    "    valid_logits = compute_logits(X_valid, W, b)\n",
    "    valid_acc = compute_accuracy(y_valid, valid_logits)\n",
    "    valid_acc_values.append(valid_acc)\n",
    "\n",
    "    # Get weight matrix and biases\n",
    "    W_fitted = W.numpy()\n",
    "    b_fitted = b.numpy()\n",
    "\n",
    "\n",
    "# Plot accuracy values\n",
    "plt.plot(train_acc_values, label=\"train\")\n",
    "plt.plot(valid_acc_values, label=\"validation\")\n",
    "plt.title(\n",
    "    \"Validation accuracy: {:.3f}\".format(\n",
    "        valid_acc_values[-1]  # Last validation accuracy value\n",
    "    )\n",
    ")\n",
    "plt.xlabel(\"batch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution - Plot templates\n",
    "---\n",
    "\n",
    "> **Exercise**: Plot the templates of each output neuron. If you use the `imshow(array)` function to plot the array of weights, remember that it expects values between zero and one for 3-dimensional arrays. You can use the `MinMaxScaler` object from Scikit-learn to rescale the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Rescale each column of the weights matrix between 0 and 1\n",
    "W_fitted_rescaled = MinMaxScaler().fit_transform(W_fitted)\n",
    "\n",
    "# Create figure with 10 subplots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=10, figsize=(13, 2))\n",
    "\n",
    "# Plot the weights for each class in a subplot\n",
    "for i, axis in enumerate(axes):\n",
    "    # Get weights of the i-th class\n",
    "    weights = W_fitted_rescaled[:, i]\n",
    "\n",
    "    # Reshape weight values into a 32x32x3 array\n",
    "    template = weights.reshape(32, 32, 3)\n",
    "\n",
    "    # Plot array\n",
    "    axis.set_title(cifar10[\"names\"][i])\n",
    "    axis.imshow(template)\n",
    "    axis.get_xaxis().set_visible(False)  # disable x-axis\n",
    "    axis.get_yaxis().set_visible(False)  # disable y-axis\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution - Evaluate model\n",
    "---\n",
    "\n",
    "> **Exercise**: Evaluate the accuracy of your network on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate validation accuracy\n",
    "test_logits = compute_logits(X_test, W, b)\n",
    "test_acc = compute_accuracy(y_test, test_logits)\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
