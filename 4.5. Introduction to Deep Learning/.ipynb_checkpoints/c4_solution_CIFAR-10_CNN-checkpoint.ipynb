{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise - Load data\n",
    "---\n",
    "\n",
    "> **Exercise**: Load the CIFAR-10 data. Normalize the images and split them into train, validation and test sets. Define a `get_batches(X, y, batch_size)` function to generate random X/y batches of size `batch_size` using a Python generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "with np.load(\"c4_cifar10-6k.npz\", allow_pickle=False) as npz_file:\n",
    "    cifar = dict(npz_file.items())\n",
    "\n",
    "# Convert pixels into floating point numbers\n",
    "data = cifar[\"data\"].astype(np.float32)\n",
    "\n",
    "# Rescale pixel values between -0.5 and 0.5\n",
    "data = (data - 128) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create train set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    # Reshape images: 32 by 32 with 3 (RGB) color channels\n",
    "    data.reshape(-1, 32, 32, 3),\n",
    "    cifar[\"labels\"],\n",
    "    test_size=2000,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "# Create validation and test sets\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "    X_test, y_test, test_size=1000, random_state=0\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Valid:\", X_valid.shape, y_valid.shape)\n",
    "print(\"Test:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch generator\n",
    "def get_batches(X, y, batch_size):\n",
    "    # Shuffle X,y\n",
    "    shuffled_idx = np.arange(len(y))  # 1,2,...,n\n",
    "    np.random.shuffle(shuffled_idx)\n",
    "\n",
    "    # Enumerate indexes by steps of batch_size\n",
    "    # i: 0, b, 2b, 3b, 4b, .. where b is the batch size\n",
    "    for i in range(0, len(y), batch_size):\n",
    "        # Batch indexes\n",
    "        batch_idx = shuffled_idx[i : i + batch_size]\n",
    "        yield X[batch_idx], y[batch_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise - Create and train a ConvNet\n",
    "---\n",
    "\n",
    "> **Exercise:** Create a convolutional neural network and train it using your batch generator. Evaluate the accuracy on the validation set after each epoch. Test different architectures and parameters. Evaluate your best network on the test set. Save the trained kernel weights of the first convolutional layer in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the layers\n",
    "\n",
    "# Convolutional layer\n",
    "conv_layer = tf.keras.layers.Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=(5, 5),\n",
    "    strides=(2, 2),\n",
    "    padding=\"SAME\",\n",
    "    activation=tf.nn.relu,\n",
    "    kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01, seed=0),\n",
    "    name=\"conv\",  # Add name\n",
    ")\n",
    "\n",
    "# Max pooling layer\n",
    "pool_layer = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"SAME\")\n",
    "\n",
    "# 2nd convolutional layer\n",
    "conv_layer2 = tf.keras.layers.Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding=\"SAME\",\n",
    "    activation=tf.nn.relu,\n",
    "    kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01, seed=0),\n",
    "    name=\"conv2\",\n",
    ")\n",
    "\n",
    "# Flatten layer\n",
    "flat_layer = tf.keras.layers.Flatten()\n",
    "\n",
    "# Dropout layer\n",
    "dropout_layer = tf.keras.layers.Dropout(rate=0.25, seed=0, name=\"dropout\")\n",
    "\n",
    "# Fully connected layer\n",
    "fc_layer = tf.keras.layers.Dense(\n",
    "    units=256,\n",
    "    activation=tf.nn.relu,  # 256 hidden units\n",
    "    kernel_initializer=tf.keras.initializers.VarianceScaling(scale=2, seed=0),\n",
    "    bias_initializer=tf.zeros_initializer(),\n",
    "    name=\"dense\",\n",
    ")\n",
    "\n",
    "# Output layer\n",
    "logits_layer = tf.keras.layers.Dense(\n",
    "    units=10,\n",
    "    activation=None,  # No activation function\n",
    "    kernel_initializer=tf.keras.initializers.VarianceScaling(scale=1, seed=0),\n",
    "    bias_initializer=tf.zeros_initializer(),\n",
    "    name=\"dense\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# Define functions used to train the graph\n",
    "\n",
    "# Compute the logits\n",
    "@tf.function\n",
    "def compute_logits(x, training):\n",
    "    conv_output = conv_layer(x)\n",
    "    pool_output = pool_layer(conv_output)\n",
    "    conv_output2 = conv_layer2(pool_output)\n",
    "    pool_output2 = pool_layer(conv_output2)\n",
    "    flat_output = flat_layer(pool_output2)\n",
    "    dropout_output = dropout_layer(flat_output, training=training)\n",
    "    fc_output = fc_layer(dropout_output)\n",
    "    logits_output = logits_layer(fc_output)\n",
    "    return logits_output\n",
    "\n",
    "\n",
    "# Compute the loss\n",
    "@tf.function\n",
    "def compute_loss(y, logits):\n",
    "    ce = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    mean_ce = tf.reduce_mean(ce)\n",
    "    return mean_ce\n",
    "\n",
    "\n",
    "# Compute the accuracy\n",
    "@tf.function\n",
    "def compute_accuracy(y, logits):\n",
    "    predictions = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
    "    is_correct = tf.equal(y, predictions)\n",
    "    acc = tf.reduce_mean(tf.cast(is_correct, dtype=tf.float32))\n",
    "    return acc\n",
    "\n",
    "\n",
    "# Train the model (optimization procedure)\n",
    "@tf.function\n",
    "def train(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = compute_logits(x, training=True)\n",
    "        loss = compute_loss(y, logits)\n",
    "    # Concatenate the tarainable variables in one list usint the '+' operation on lists\n",
    "    variables = (\n",
    "        conv_layer.trainable_variables\n",
    "        + conv_layer2.trainable_variables\n",
    "        + fc_layer.trainable_variables\n",
    "        + logits_layer.trainable_variables\n",
    "    )\n",
    "\n",
    "    optimizer.minimize(loss=loss, var_list=variables, tape=tape)\n",
    "    return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation accuracy\n",
    "valid_acc_values = []\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Train several epochs\n",
    "for epoch in range(15):\n",
    "    # Accuracy values (train) after each batch\n",
    "    batch_acc = []\n",
    "\n",
    "    # Get batches of data\n",
    "    for X_batch, y_batch in get_batches(X_train, y_train, 64):\n",
    "        # Run training\n",
    "        batch_logits, _ = train(X_batch, y_batch)\n",
    "\n",
    "        # Evaluate training accuracy (on current batch)\n",
    "        acc = compute_accuracy(y_batch, batch_logits)\n",
    "        batch_acc.append(acc)\n",
    "\n",
    "    # Evaluate validation accuracy (on the whole data)\n",
    "    valid_logits = compute_logits(X_valid, training=False)\n",
    "    valid_acc = compute_accuracy(y_valid, valid_logits)\n",
    "    valid_acc_values.append(valid_acc)\n",
    "\n",
    "    # Print progress\n",
    "    print(\n",
    "        \"Epoch {} - valid: {:.3f} train: {:.3f} (mean)\".format(\n",
    "            epoch + 1, valid_acc, np.mean(batch_acc)\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Get 1st conv. layer kernels\n",
    "kernels = conv_layer.kernel\n",
    "\n",
    "# Evaluate test accuracy after training\n",
    "test_logits = compute_logits(X_test, training=False)\n",
    "test_acc = compute_accuracy(y_test, test_logits)\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot accuracy values\n",
    "plt.plot(valid_acc_values)\n",
    "plt.title(\n",
    "    \"Validation accuracy: {:.3f} (mean last 3)\".format(\n",
    "        np.mean(valid_acc_values[-3:])  # last three values\n",
    "    )\n",
    ")\n",
    "plt.xlabel(\"batch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise - Visualize kernels\n",
    "---\n",
    "\n",
    "> **Exercise**: Plot the kernels from the first convolutional layer with the `imshow()` function.\n",
    "\n",
    "**Hint**: Remember that the `imshow()` function expects values between 0 and 1 for 3-dimensional arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid of subplots\n",
    "fig, axes = plt.subplots(nrows=8, ncols=8, figsize=(4, 4))\n",
    "\n",
    "# Remove gaps between suplots\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "# Plot the 64 kernels from the first convolutional layer\n",
    "for i, axis in enumerate(axes.flatten()):\n",
    "    # Get i-th kernel (shape: 5x5x3)\n",
    "    kernel = kernels[:, :, :, i].numpy().copy()\n",
    "\n",
    "    # Rescale values between 0 and 1\n",
    "    kernel -= kernel.min()  # Rescale between 0 and max\n",
    "    kernel /= kernel.max()  # Rescale between 0 and 1\n",
    "\n",
    "    # Plot kernel with imshow()\n",
    "    axis.imshow(kernel)\n",
    "    axis.get_xaxis().set_visible(False)  # disable x-axis\n",
    "    axis.get_yaxis().set_visible(False)  # disable y-axis\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional - Plot activation maps\n",
    "---\n",
    "\n",
    "> Pick an input image and plot the convolutional output of this image for each kernel to create, i.e. the **activation maps**.\n",
    "\n",
    "**Hint**: The solution notebook from the previous unit shows already how this can be done for the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a sample image and get 1st conv. activations\n",
    "activation_maps = conv_layer(np.expand_dims(X_valid[5], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print shape of the variable\n",
    "print(\"Activation maps:\", activation_maps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot input image\n",
    "img = X_valid[5]\n",
    "img -= img.min()\n",
    "img /= img.max()\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with subplots\n",
    "fig, axes = plt.subplots(nrows=8, ncols=8, figsize=(8, 8))\n",
    "\n",
    "# Plot the activation maps of the 1st conv. layer for the sample image\n",
    "for i, axis in enumerate(axes.flatten()):\n",
    "    # Get activation map of the i-th filter\n",
    "    activation = activation_maps[0, :, :, i]\n",
    "\n",
    "    # Plot it with imshow()\n",
    "    axis.set_title(\"map {}\".format(i + 1))\n",
    "    axis.imshow(activation)\n",
    "    axis.get_xaxis().set_visible(False)  # disable x-axis\n",
    "    axis.get_yaxis().set_visible(False)  # disable y-axis\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
