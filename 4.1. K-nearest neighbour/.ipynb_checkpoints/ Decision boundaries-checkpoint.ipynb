{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d42c353e-4efb-4cf4-a233-20b1e2cecacd",
   "metadata": {},
   "source": [
    "**Decision Boundaries**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a830b11c-6a5c-4b7f-8c09-dba75d961f9b",
   "metadata": {},
   "source": [
    " There is a relationship between k and the complexity or amount of “corner cases rules” of our k-NN classifier. Note that k is a hyperparameter since we set it before applying the algorithm. Hence, we tune it using grid search in practice.\n",
    "\n",
    "In the next units, we will work on the heart disease diagnosis dataset. We will first see how to set a baseline for this classification task and then try with k-NN using Scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7841dd0-36a7-497f-8ab9-d40414179372",
   "metadata": {},
   "source": [
    "**Example**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9b251e-74d6-4ad3-84d0-35b579db7372",
   "metadata": {},
   "source": [
    "The goal is to diagnose the presence (or absence) of a heart disease based on a set of observations for each patient\n",
    "\n",
    "* age - the age of the patient\n",
    "* trestbps - the resting blood pressure in mm Hg\n",
    "* chol - the amount of cholesterol in mg/dl\n",
    "* thalach - maximum heart rate during the tests\n",
    "* oldpeak - another measure obtained using an electrocardiogram\n",
    "* ca - the number of major vessels colored by fluoroscopy\n",
    "* Our goal is to use these features to predict a target disease variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "640850e6-7ff4-47ac-8b10-c79b820c2c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ca</th>\n",
       "      <th>disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>150</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>absence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>108</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>presence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>129</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>presence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>187</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>absence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>172</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>absence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  trestbps  chol  thalach  oldpeak  ca   disease\n",
       "0   63       145   233      150      2.3   0   absence\n",
       "1   67       160   286      108      1.5   3  presence\n",
       "2   67       120   229      129      2.6   2  presence\n",
       "3   37       130   250      187      3.5   0   absence\n",
       "4   41       130   204      172      1.4   0   absence"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "data_df = pd.read_csv(\"c4_heart-numerical.csv\")\n",
    "\n",
    "# First five rows\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a85116-8b2c-4f57-912a-cff33e1598c9",
   "metadata": {},
   "source": [
    "* We can see that all variables are numerical except the target one which has two possible values: presence and absence. We can verify that using Numpy unique() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7953f287-0392-445d-aa74-91c8602bc523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (303, 6) float64\n",
      "y: (303,) object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create X/y arrays\n",
    "X = data_df.drop(\"disease\", axis=1).values\n",
    "y = data_df.disease.values\n",
    "print(\"X:\", X.shape, X.dtype)\n",
    "print(\"y:\", y.shape, y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cb4b1a8-a5c2-4133-8f27-b82f1722f39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['absence' 'presence']\n"
     ]
    }
   ],
   "source": [
    "# Print labels\n",
    "labels = np.unique(y)\n",
    "print(\"Labels:\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355bb4f8-7cf6-4d85-a826-d1292914dfb9",
   "metadata": {},
   "source": [
    "* Let’s now split the data into train/test sets. This time, we will use a 70-30 train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c55d603f-6b07-4e6a-b64c-98171262a048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (212, 6) (212,)\n",
      "Test set: (91, 6) (91,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(\"Train set:\", X_tr.shape, y_tr.shape)\n",
    "print(\"Test set:\", X_te.shape, y_te.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e400335-4176-4519-b95a-69dc040abe11",
   "metadata": {},
   "source": [
    "The code to load and split the dataset is similar to what we saw for regression tasks. The only difference is that the output vector y contains categorical values instead of continuous ones.\n",
    "\n",
    "Before fitting k-NN, let’s first define the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ac7023-027e-4bea-9d1a-d358a4922876",
   "metadata": {},
   "source": [
    "**BASELINE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5d43b4-159a-4dec-a37b-b5ef993c5ef7",
   "metadata": {},
   "source": [
    "The “most frequent” baseline: We saw that it makes sense to predict the mean or median of the target variable for regression tasks. In the classification case, we can predict the most frequent category.In our example, there are only two categories and the most frequent one is 'absence'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68de0d2d-99b7-49f1-8bd3-347551fcdb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total absence: 117\n"
     ]
    }
   ],
   "source": [
    "# Count the number of entries labeled with 'absence'\n",
    "n_absence = np.sum(y_tr == \"absence\")\n",
    "\n",
    "print(\"Total absence:\", n_absence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50f24f6-1963-42ff-93b0-eb3696c86b03",
   "metadata": {},
   "source": [
    "We use Numpy sum() on an array of boolean values to count the number of True entries. We get that 117 of the 212 patients from the training set are labeled with 'absence'. In other words, the proportion of patients not diagnosed with the heart disease is around 55%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88e29086-7205-4fdc-ada5-92b060967304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of absence: 0.55\n"
     ]
    }
   ],
   "source": [
    "# Probability of 'absence'\n",
    "p_absence = n_absence / len(y_tr)\n",
    "\n",
    "print(\"Probability of absence: {:.2f}\".format(p_absence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a9efba-c3dd-4a3f-bd89-50dc45b14d4f",
   "metadata": {},
   "source": [
    "Note that we used the train_test_split() function which shuffles the data before splitting. Hence, the train and test sets are good samples of the data, and they should have approximately the same proportion of patients in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8be3f9a-1151-490b-88b2-3af8092ba7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of absence: 0.52\n"
     ]
    }
   ],
   "source": [
    "# On the test set\n",
    "p_absence_te = np.sum(y_te == \"absence\") / len(y_te)\n",
    "\n",
    "print(\"Probability of absence: {:.2f}\".format(p_absence_te))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08d1d98-3678-4d34-ba42-052bafeb81a4",
   "metadata": {},
   "source": [
    "The number 0.52 is the accuracy of the baseline model. It corresponds to the proportion of data points from the test set that the model classified correctly. In classification tasks, this is often what we want to maximize. Similarly, the error rate is the proportion of data points misclassified. In our case, the error rate of the “most frequent” baseline is 0.48.\n",
    "\n",
    "In general, the accuracy of the “most frequent” baseline should be equal to the percentage of samples in the most frequent category. Hence, it’s only better than random guessing when the distribution of the target variable is not uniform. In our case, the dataset contains approximately the same number of patients labeled with absence and presence. Hence, it’s accuracy is very close to 50% which corresponds to random guessing for two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc6b32a-37e6-4f6e-87d1-fe1149487f7d",
   "metadata": {},
   "source": [
    "**Multiple classes**\n",
    "The code from above doesn’t scale well to target variables with many categories because we have to count the number of entries in each one manually. One solution is to use value_counts(list) from Pandas which groups the entries by values and counts the number of entries in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "578fdca9-6980-41a5-83c0-0c8d64ddd4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "absence     0.551887\n",
       "presence    0.448113\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute distribution using Pandas\n",
    "pd.Series(y_tr).value_counts() / len(y_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb16cda2-1034-4846-a8b1-c619bcbf18ff",
   "metadata": {},
   "source": [
    "**OPTION** In this code, we normalize the counts by the total number of entries to get a probability, but we could also use normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2511ba0-5f40-4d85-be66-78d616df4126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "absence     0.551887\n",
       "presence    0.448113\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute distribution using Pandas\n",
    "pd.Series(y_tr).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdd836f-86f8-4f08-98a8-4c8221185da8",
   "metadata": {},
   "source": [
    "Scikit-learn provides a DummyClassifier() to compute baselines for classification tasks. We can set its strategy parameter to 'most_frequent' to get the baseline from above\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65610c6b-768c-4dbd-81e4-d9ef586d8acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Create the dummy classifier\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b624ff57-039d-4607-9a63-23228ed80546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.52\n"
     ]
    }
   ],
   "source": [
    "#Let’s fit and evaluate our baseline estimator\n",
    "\n",
    "# Fit it\n",
    "dummy.fit(None, y_tr)\n",
    "\n",
    "# Compute test accuracy\n",
    "accuracy = dummy.score(None, y_te)\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaf7f9c-9200-483a-91a1-9671255b6450",
   "metadata": {},
   "source": [
    "One important difference with regression: Scikit-learn classifiers return the accuracy instead of R2 coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73416b4-82f0-48a8-8eb9-ad0f78b2c757",
   "metadata": {},
   "source": [
    "**Confusion matrix**\n",
    "So far in this unit, we reported the accuracy score of our predictions which simply corresponds to the number of times our predictions match the true correct label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d909241-7c3a-464d-bed4-7a9e93e45444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: ['absence' 'absence' 'absence' 'absence' 'absence'] ..\n",
      "True labels: ['absence' 'absence' 'presence' 'absence' 'presence'] ..\n"
     ]
    }
   ],
   "source": [
    "# \"Most-frequent\" predictions\n",
    "y_pred_absence = dummy.predict(X_te)\n",
    "print(\"Predicted:\", y_pred_absence[:5], \"..\")\n",
    "print(\"True labels:\", y_te[:5], \"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac48c445-c2dc-4b07-ad02-19637257ec15",
   "metadata": {},
   "source": [
    "However, it’s usually helpful to investigate where errors occur. This can be done by plotting the confusion matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10deda96-68f7-4e4c-8da5-c02a9b2d960e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47  0]\n",
      " [44  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Confusion matrix\n",
    "matrix = confusion_matrix(y_true=y_te, y_pred=y_pred_absence)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31956fa9-91ad-47f6-b2eb-102f2713a143",
   "metadata": {},
   "source": [
    "This is simply a frequency table that shows how many times we predicted some class versus how many times it is actually that class or another one i.e. a frequency table of predictions versus true class\n",
    "\n",
    "The table is easier to visualize as a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccb4d138-6c85-431a-bc98-a171d0c93c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred: absence</th>\n",
       "      <th>pred: presence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true: absence</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true: presence</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pred: absence  pred: presence\n",
       "true: absence              47               0\n",
       "true: presence             44               0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix as a DataFrame\n",
    "matrix_df = pd.DataFrame(\n",
    "    matrix,\n",
    "    columns=[\"pred: absence\", \"pred: presence\"],\n",
    "    index=[\"true: absence\", \"true: presence\"],\n",
    ")\n",
    "\n",
    "matrix_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3b5d15-2731-4a9c-999f-08a3c8158e5e",
   "metadata": {},
   "source": [
    "In our case, we can see that our “most-frequent” baseline always predicts “absence” .. which is correct 47 times, and incorrect 44 times.\n",
    "\n",
    "From this matrix, we can derive two important metrics: the recall and precision of our classifier. Those scores are defined in terms of the number of true or false positives/negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5861a8b7-cca7-4602-8b13-0301a50af6a5",
   "metadata": {},
   "source": [
    "Intuitively, the precision answers “How many times are we correct when we predict positive?”. The formula is simply\n",
    "\n",
    "**precision = tp/(tp+fp)**\n",
    "\n",
    "We can compute it in Scikit-learn using precision_score()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8738eb2f-e94c-43b5-9ded-09e2ec46ac3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\56975\\anaconda3\\envs\\adsml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_true=y_te, y_pred=y_pred_absence, pos_label=\"presence\")\n",
    "# Returns: \"UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6635a209-05ed-4962-a3ec-c326ab7aadb8",
   "metadata": {},
   "source": [
    "You should get an error message saying “UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.”. This is due to the fact that precision is not defined since our “most-frequent” baseline never predicts ‘presence’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac33553f-b6e2-4d15-8fd8-97e6f87bbedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the value of precision\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18cb1be6-f3fc-4219-9000-0759a75bacfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4835164835164835"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#However, we can compute it for a “always predicts presence” baseline\n",
    "# Precision of the \"always predicts presence\" baseline\n",
    "y_pred_presence = np.full_like(y_te, fill_value=\"presence\")\n",
    "precision_score(y_true=y_te, y_pred=y_pred_presence, pos_label=\"presence\")  # ~ 0.48\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4464cfae-3616-444d-ba74-a41ab06f410d",
   "metadata": {},
   "source": [
    "ntuitively, the recall measures “How many times do we predict positive when it is?”. The formula is simply\n",
    "\n",
    "**recall = tp/(tp+fn)**\n",
    "\n",
    "We can compute it in Scikit-learn using recall_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fc507b1-e891-4556-bffb-9e16567d18b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "recall_score(y_true=y_te, y_pred=y_pred_absence, pos_label=\"presence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b044bfa4-b8e7-4337-bcc1-7e10714b4c70",
   "metadata": {},
   "source": [
    "Our “most-frequent” baseline never predicts ‘presence’ when the disease is present, so the recall score is 0.0 in our case.\n",
    "\n",
    "However, we can get a score of 1.0 with the “always predicts presence” baseline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a85e212f-b044-4b87-8620-abf52ae808a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall of the \"always predicts presence\" baseline\n",
    "recall_score(y_true=y_te, y_pred=y_pred_presence, pos_label=\"presence\")  # 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b557855-b186-4832-a1fb-4116587b5f53",
   "metadata": {},
   "source": [
    "**F1 SCORE**\n",
    "The F1 score is a way to combine the precision and recall metrics into a single score. The formula is\n",
    "\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "Again, we can compute it in Scikit-learn using f1_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "076c27ab-096b-4acd-a21f-a24ad9557c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6518518518518518"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_true=y_te, y_pred=y_pred_presence, pos_label=\"presence\")  # ~0.65"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1c73f4-7ae7-408b-b0b2-30a1d95b5c32",
   "metadata": {},
   "source": [
    "**Classification report**\n",
    "It’s common to print those metrics when analyzing the performance of classifiers. For this reason, Scikit-learn provides a classification_report() function that gives the different scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1aa85e47-a344-4c43-a526-664274e3709f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     absence       0.00      0.00      0.00        47\n",
      "    presence       0.48      1.00      0.65        44\n",
      "\n",
      "    accuracy                           0.48        91\n",
      "   macro avg       0.24      0.50      0.33        91\n",
      "weighted avg       0.23      0.48      0.32        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_true=y_te, y_pred=y_pred_presence, zero_division=0.0)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4363860e-a617-42bd-957c-0d4a8fa146c6",
   "metadata": {},
   "source": [
    "The table shows the different scores depending on the positive class i.e. absence or presence\n",
    "\n",
    "In this table, support corresponds to the number of points in each class. Macro and weighted averages refer to different ways to combine the results when there are multiple classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac08fd-8e39-4207-b4e9-4c01ce85cf6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:adsml] *",
   "language": "python",
   "name": "conda-env-adsml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
