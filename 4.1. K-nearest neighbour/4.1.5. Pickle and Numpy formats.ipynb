{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae949f08-09a7-43df-bb36-49d61f2f1de5",
   "metadata": {},
   "source": [
    "**Pickle and Numpy formats**\n",
    "\n",
    "So far, we used datasets stored in .csv files. Working with this format has many advantages. It’s well supported by many data analysis software like Pandas and Excel, and it’s a text format which means that we can easily edit them with a text editor. However, they are limited to tabular data, and they are not particularly optimized to work with large arrays of values.\n",
    "\n",
    "In this unit, we will see how to store/load Python objects and Numpy arrays using the Pickle .p and the Numpy .npy and .npz binary formats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc93690-a7c8-471a-8274-c07f9b49eb3b",
   "metadata": {},
   "source": [
    "**Create Pickle files**\n",
    "\n",
    "A Pickle file is a very convenient way to store some data in Python. This format works with many Python objects and data structures, and it’s cross-platform which means that we can use these files across different platforms ex. Windows, macOS, Linux.\n",
    "\n",
    "Let’s take an example. We will start by storing a simple dictionary with two lists.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d082a544-b716-43c4-9b81-b86f29c2e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dictionary with two lists\n",
    "data = {\n",
    "    'x': [6.28318, 2.71828, 1],\n",
    "    'y': [2, 3, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76db7eae-f5b5-4a8a-a74e-4f3a650b69d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to import the pickle library.\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9131639-1653-42a7-88b0-41e5781dfe3a",
   "metadata": {},
   "source": [
    "We can then use the Pickle dump() function to store the data variable into a Pickle .p file. But first, we need to create it using the Python open() function. **Pickle files are binary, i.e., they are not text files. For this reason, we need to use the wb flags (writing and binary mode).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d687862-e84f-410c-8612-6da6f203dd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionary into a pickle file\n",
    "with open('data.p', 'wb') as file:\n",
    "    pickle.dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aede19-7032-4a0c-9f38-12c4539fded3",
   "metadata": {},
   "source": [
    "It’s important to understand that Pickle is a binary format. We can take a look at the content of the data.p file by typing the xxd -b data.p command in a terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f8019a-050b-47c6-a209-7d1f3b139d16",
   "metadata": {},
   "source": [
    "The command returns an eight-column representation of the data.p file. The first one is a count of the number of bytes and indicates how far we are from the start of the file. The next six columns show its binary content by groups of eight bits (also known as bytes) and the last column is the text representation of each byte.\n",
    "\n",
    "As you can see, unlike CSV files, we cannot open data.p with a text editor and edit the text representation of the Python dictionary directly. To modify its content, we need to open, edit and save the changes using Python code. Let’s see how to do that.\n",
    "\n",
    "**Edit Pickle files**\n",
    "\n",
    "The Pickle library implements a load() function to read the content of a Pickle file. Let’s use it to read our data.p file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d02654ac-4694-41c9-b84c-f94d36101c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': [6.28318, 2.71828, 1], 'y': [2, 3, 5]}\n"
     ]
    }
   ],
   "source": [
    "# Load the pickle file\n",
    "with open('data.p', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b96acc-56bb-4865-9283-637f4f14abef",
   "metadata": {},
   "source": [
    "This time, we are reading and not writing the file. Hence, we need to pass the rb flags to the open() function (reading and binary mode).\n",
    "\n",
    "We can now edit the dictionary using Python code and store the modified version with another dump() instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba6160dc-050f-41c4-82fd-4cd369fc11b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new element to each list\n",
    "data['x'].append(0)\n",
    "data['y'].append(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "725cfef9-b8c8-49af-9d8f-fd037ab81468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It would then be straightforward to save our modifications:\n",
    "# Save our modifications\n",
    "with open('data.p', 'wb') as file:\n",
    "    pickle.dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96594361-0645-4be8-a974-bc57a1cb8e46",
   "metadata": {},
   "source": [
    "In practice, Pickle files are often used to store machine learning datasets. In a typical scenario, we have a train.p and a test.p file. Both contain a dictionary with the array of features, the target values and optionally some meta information such as the names of the categories for classification tasks.\n",
    "\n",
    "Pickle files are very convenient since they work with a large number of Python objects. However, it’s possible to store and execute arbitrary (and potentially malicious) code with them. For this reason, you should always verify the integrity of your Pickle files before loading them.\n",
    "\n",
    "We will now see another way to store our datasets using the Numpy .npy and .npz formats which are specifically designed to store potentially large Numpy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2542202-c7bc-4d8c-afc1-510028a6afdd",
   "metadata": {},
   "source": [
    "**Numpy npy files**\n",
    "\n",
    "Numpy implements a .npy binary format. It has two main advantages.\n",
    "\n",
    "* Unlike Pickle files, it doesn’t duplicate the data in memory before loading or saving the file which is very convenient for large datasets.\n",
    "* It implements memory-mapping which allows reading small parts of a large dataset without loading the entire file into memory.\n",
    "For these reasons, it’s the recommended way to store Numpy arrays. Let’s take an example. This time, we will save a Numpy array with three values of type float16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cf13c18-3772-4269-b8a3-a3de4ebcfc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create the Numpy array\n",
    "data = np.array([6.28318, 2.71828, 1], dtype=np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5bdbca-c5de-460e-8331-bf38ce89d973",
   "metadata": {},
   "source": [
    "We can now store this array using the Numpy save() function. Unlike the Pickle dump() one, we don’t need to open the file beforehand with open(). Numpy will automatically create and manage the file object for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5284efad-a548-440a-841a-21f82b61f050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it into a .npy file\n",
    "np.save('data.npy', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2018bf7-b60d-47de-a41b-15dbb3045902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.28 , 2.719, 1.   ], dtype=float16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the file is also straightforward.\n",
    "# Read it\n",
    "np.load('data.npy') # array([6.28 , 2.719, 1.   ], dtype=float16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696055dd-dcaf-4056-a821-af68e067a7a9",
   "metadata": {},
   "source": [
    "The .npy format is made to store Numpy arrays, but it’s also possible to use the save() function to store other data structures such as dictionaries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "256c6349-7549-43d7-8f04-4f32ae515bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'x': array([6.28 , 2.719, 1.   ], dtype=float16), 'y': array([2, 3, 5])},\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'x': np.array([6.28318, 2.71828, 1], dtype=np.float16),\n",
    "    'y': np.array([2, 3, 5])\n",
    "}\n",
    "\n",
    "# Save it into a .npy file\n",
    "np.save('data.npy', data)\n",
    "\n",
    "# Read it\n",
    "np.load('data.npy',allow_pickle=True)\n",
    "\n",
    "# Note: Numpy wraps the dictionary in an array of\n",
    "# type `object` and uses pickle to save that object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9f97f5-ef72-4956-b546-83ff63e56b0d",
   "metadata": {},
   "source": [
    "In this case, Numpy wraps the data dictionary in a Numpy array with the object data type and saves its content using Pickle. In other words, the file has the .npy extension but contains a Pickle object.\n",
    "\n",
    "Note that by default Numpy disallows Pickle (e.g., for security reasons) with the allow_pickle argument.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3c6d46f-314a-41f6-849c-4a830f5db625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object arrays cannot be loaded when allow_pickle=False\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    np.load('data.npy', allow_pickle=False)\n",
    "except Exception as e:\n",
    "    print(e) # Object arrays cannot be loaded when allow_pickle=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2336a943-9426-425c-8fe7-a1468041673e",
   "metadata": {},
   "source": [
    "This code raises an error because the data.npy file contains a Pickle object.\n",
    "\n",
    "In our machine learning tasks, we usually want to work with a single file that contains both the array of features and the array of target values. We will now see how to do that without using the “array of objects” trick from above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d27bb4d-3eb2-4d2b-ba33-8292e73bb687",
   "metadata": {},
   "source": [
    "**The Numpy npz format**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aacf0cb-0efb-401f-8b90-5cb610fb99c9",
   "metadata": {},
   "source": [
    "It’s possible to store multiple arrays using the Numpy .npz format. Let’s take an example. Say that we want to save the x and y arrays from above into a single file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b38c9a6f-a4ae-4c93-a82b-7c7dfff3827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two Numpy arrays\n",
    "x = np.array([6.28318, 2.71828, 1], dtype=np.float16)\n",
    "y = np.array([2, 3, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32aa592-7401-4b9b-a619-27d6276bbec8",
   "metadata": {},
   "source": [
    "To achieve this, we need to use the savez() function. In our case, we will pass the two arrays as arguments, but you can use it to save any number of arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c75e1d0-ac05-4c77-8adb-d3f4af2e8fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save them into a .npz file\n",
    "np.savez('data.npz', features=x, targets=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67293cde-7ccd-4768-8efe-c7150ef4c810",
   "metadata": {},
   "source": [
    "Note that we need to label each array. We chose to use the names features and targets, but you can try with other labels. We use these labels to refer to each array when loading the data.npz file with the load() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d01cbcf-8f8f-416d-89a8-e16120793602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['features', 'targets']\n",
      "x: [6.28  2.719 1.   ]\n",
      "y: [2 3 5]\n"
     ]
    }
   ],
   "source": [
    "# Load the npz file\n",
    "with np.load('data.npz', allow_pickle=False) as npz_file:\n",
    "    # It's a dictionary-like object\n",
    "    print(list(npz_file.keys()))\n",
    "\n",
    "    # Load the arrays\n",
    "    print('x:', npz_file['features'])\n",
    "    print('y:', npz_file['targets'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3d9844-7536-42e2-aed2-998e2f927061",
   "metadata": {},
   "source": [
    "Unlike .npy files, the load() function doesn’t return the content of the file directly but rather an NpzFile dictionary-like object which performs lazy loading, i.e., it loads the arrays only when we access them. For this reason, we need to use a **with statement** to manage the file resource.\n",
    "\n",
    "This also implies that we cannot use the npz_files variable to read the arrays outside the **with** statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5de70101-70ea-42ef-aff1-faa9274ab3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: [2 3 5]\n",
      "'NoneType' object has no attribute 'open'\n"
     ]
    }
   ],
   "source": [
    "with np.load('data.npz', allow_pickle=False) as npz_file:\n",
    "    # Read the \"y\" array (inside the with statement)\n",
    "    print('y:', npz_file['targets'])\n",
    "\n",
    "# Read the \"y\" array (outside the with statement)\n",
    "try:\n",
    "    print('y:', npz_file['targets'])\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6ba8e2-4fa4-4608-9466-037def809b35",
   "metadata": {},
   "source": [
    "The reason is that Python closes the data.npz file after the last line of the with statement and we cannot read anymore its content. One solution is to load the arrays into an x and a y variable inside the with statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f952af19-05f4-428c-97ca-a3c59526154c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [6.28  2.719 1.   ]\n",
      "y: [2 3 5]\n"
     ]
    }
   ],
   "source": [
    "with np.load('data.npz', allow_pickle=False) as npz_file:\n",
    "    # Load the arrays\n",
    "    x = npz_file['features']\n",
    "    y = npz_file['targets']\n",
    "\n",
    "print('x:', x)\n",
    "print('y:', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816ae9ac-3e5a-41a8-982a-e317b9e36e88",
   "metadata": {},
   "source": [
    "In this code, we get the (label, array) pairs using the item() function and build a {label: array} dictionary from them using the Python dict() function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1c4de9-ab20-4bae-bab6-2cba8329b7b5",
   "metadata": {},
   "source": [
    "We now know three different formats to store our data using Python.\n",
    "\n",
    "* .csv files to store tabular data\n",
    "* Pickle .p files for Python objects\n",
    "* .npy and .npz files for (potentially large) Numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0924a4e-ab3a-4413-ac98-e1f41a33c777",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:adsml] *",
   "language": "python",
   "name": "conda-env-adsml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
