{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bike sharing linear regression\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution - Load train/test sets & remove collinear features\n",
    "---\n",
    "\n",
    "> **Exercise**: Load the train/test sets into the `X_tr`, `y_tr`, `X_te` and `y_te` variables. Remove features that make the `X_tr` matrix, with the additional column of ones, rank deficient. Also, you might want to remove nearly collinear features if they hurt performance.\n",
    "\n",
    "**Self-assessment**: Verify that the `X_tr` matrix with the additional column of ones has full rank. Compute its condition number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load train data\n",
    "train_df = pd.read_csv(\"c3_bike-train.csv\")\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv(\"c3_bike-test.csv\")\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Remove collinear features\n",
    "features = [\n",
    "    \"temp\",\n",
    "    \"hum\",\n",
    "    \"windspeed\",\n",
    "    \"yr\",\n",
    "    \"workingday\",\n",
    "    \"holiday\",\n",
    "    #'atemp', # Nearly collinear column, may hurt performance\n",
    "    #'temp_C', 'atemp_C' # Collinear columns\n",
    "]\n",
    "# Note: You could use atemp instead of temp.\n",
    "\n",
    "# Create input matrix with the additional column of ones\n",
    "X = train_df[features].values  # Train data\n",
    "X1 = np.c_[np.ones(X.shape[0]), X]  # Add the column of ones\n",
    "\n",
    "# Compute rank and condition number\n",
    "M = X1.shape[1]  # Number of columns\n",
    "rank = np.linalg.matrix_rank(X1)\n",
    "cond = np.linalg.cond(X1)\n",
    "print(\"Columns {} rank {} collinear {}\".format(M, rank, M - rank))\n",
    "print(\"Condition number:\", cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract X/y Numpy variables\n",
    "X_tr = train_df[features].values\n",
    "y_tr = train_df.casual.values\n",
    "\n",
    "X_te = test_df[features].values\n",
    "y_te = test_df.casual.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution - Fit a linear regression model\n",
    "---\n",
    "\n",
    "> **Exercise**: (A) Fit a linear regression model to the `X_tr`, `y_tr` variables. Evaluate its performance on the test set using the mean absolute error (MAE). (B) Also, try fitting a linear regression with the Huber loss. (C) Pick one feature (e.g., temperatures) and plot the predictions from your best model (e.g., temperature vs. casual users plot).\n",
    "\n",
    "**Note**: Your models might predict a negative number of users. In this case, you might want to set a lower limit with the Numpy `maximum()` function to improve performance, e.g. `y_pred = np.maximum(y_pred, 50)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models with mean absolute error (MAE)\n",
    "def MAE(y, y_pred):\n",
    "    return np.mean(np.abs(y - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Linear regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_tr, y_tr)  # Fit to train data\n",
    "y_pred_lr = np.maximum(\n",
    "    lr.predict(X_te), 50  # Predictions for test data  # Set a lower limit\n",
    ")\n",
    "mae_lr = MAE(y_te, y_pred_lr)\n",
    "print(\"MAE linear regression: {:.3f}\".format(mae_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "# Huber loss\n",
    "huber = HuberRegressor(epsilon=1.45)\n",
    "huber.fit(X_tr, y_tr)  # Fit to train data\n",
    "y_pred_huber = np.maximum(\n",
    "    huber.predict(X_te), 50  # Predictions for test data  # set a lower limit\n",
    ")\n",
    "mae_huber = MAE(y_te, y_pred_huber)\n",
    "print(\"MAE Huber: {:.3f}\".format(mae_huber))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot models\n",
    "temp_te = X_te[:, 0]  # 0: temperatures column\n",
    "plt.scatter(temp_te, y_te, s=10, label=\"test points\")\n",
    "plt.scatter(temp_te, y_pred_huber, s=10, label=\"predictions (huber)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution - Separate sources and fit two linear regressions\n",
    "---\n",
    "\n",
    "We saw in the course that we can identify two sources in the data.\n",
    "\n",
    "1. Data points collected during working days\n",
    "1. Data points collected during non-working days\n",
    "\n",
    "The goal of this exercise is to create a model for each source and see whether this improves performance.\n",
    "\n",
    "> **Exercise**: Create a model for each source and evaluate the overall performance on the test set using MAE. Compare your models to a baseline using a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can identify two sources\n",
    "temp_tr = X_tr[:, 0]  # 0: temp column\n",
    "wd_tr = X_tr[:, 4]  # 4: workingday column\n",
    "\n",
    "plt.scatter(temp_tr, y_tr, c=wd_tr, s=10)\n",
    "plt.colorbar(label=\"working day\")\n",
    "plt.xlabel(\"temperatures\")\n",
    "plt.ylabel(\"casual users\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data points\n",
    "# * wd: working day\n",
    "# * nwd: non-working day\n",
    "columns = [0, 1, 2, 3, 5]  # Also, remove column 4: workingday\n",
    "\n",
    "# Train set\n",
    "wd_idx_tr = X_tr[:, 4] == 1  # Entries with workingday == 1\n",
    "\n",
    "X_tr_wd = X_tr[wd_idx_tr][:, columns]\n",
    "y_tr_wd = y_tr[wd_idx_tr]\n",
    "\n",
    "X_tr_nwd = X_tr[~wd_idx_tr][:, columns]\n",
    "y_tr_nwd = y_tr[~wd_idx_tr]\n",
    "\n",
    "# Test set\n",
    "wd_idx_te = X_te[:, 4] == 1  # Entries with workingday == 1\n",
    "\n",
    "X_te_wd = X_te[wd_idx_te][:, columns]\n",
    "y_te_wd = y_te[wd_idx_te]\n",
    "\n",
    "X_te_nwd = X_te[~wd_idx_te][:, columns]\n",
    "y_te_nwd = y_te[~wd_idx_te]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "lr_wd = LinearRegression()  # Model for working days\n",
    "lr_nwd = LinearRegression()  # Model for non-working days\n",
    "\n",
    "lr_wd.fit(X_tr_wd, y_tr_wd)  # Fit models to train data\n",
    "lr_nwd.fit(X_tr_nwd, y_tr_nwd)\n",
    "\n",
    "y_pred_lr_wd = np.maximum(\n",
    "    lr_wd.predict(X_te_wd), 50  # Predictions for test data  # set a lower limit\n",
    ")\n",
    "y_pred_lr_nwd = np.maximum(\n",
    "    lr_nwd.predict(X_te_nwd), 50  # Same for non-working days  # set a lower limit\n",
    ")\n",
    "\n",
    "# Reassemble test data and predictions\n",
    "# target values\n",
    "y_te_wdnwd = np.concatenate((y_te_wd, y_te_nwd))\n",
    "\n",
    "# predictions\n",
    "y_pred_lr_wdnwd = np.concatenate((y_pred_lr_wd, y_pred_lr_nwd))\n",
    "\n",
    "# Compute MAE\n",
    "mae_lr_wdnwd = MAE(y_te_wdnwd, y_pred_lr_wdnwd)\n",
    "print(\"MAE linear regression: {:.3f}\".format(mae_lr_wdnwd))\n",
    "\n",
    "# Plot temperatures for working days and non-working days\n",
    "temp_te_wdnwd = np.concatenate((X_te_wd[:, 0], X_te_nwd[:, 0]))\n",
    "plt.scatter(temp_te_wdnwd, y_te_wdnwd, s=10, label=\"test points\")\n",
    "\n",
    "# Predictions for working days\n",
    "plt.scatter(X_te_wd[:, 0], y_pred_lr_wd, s=10, label=\"workind day model\")\n",
    "\n",
    "# Predictions for non-working days\n",
    "plt.scatter(X_te_nwd[:, 0], y_pred_lr_nwd, s=10, label=\"non-working day model\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create baseline\n",
    "mae_baseline = MAE(y_te, np.median(y_tr))\n",
    "\n",
    "# Final comparison\n",
    "mae_values = [mae_baseline, mae_lr, mae_huber, mae_lr_wdnwd]\n",
    "titles = [\"median\", \"lr\", \"huber\", \"lr two models\"]\n",
    "\n",
    "xcor = np.arange(len(mae_values))\n",
    "plt.bar(xcor, mae_values)\n",
    "plt.xticks(xcor, titles)\n",
    "\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution - R^2 coefficient\n",
    "---\n",
    "\n",
    "> **Exercise**: Compute the $R^{2}$ coefficient of your different models on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 coefficients\n",
    "r2_lr = lr.score(X_te, y_te)\n",
    "r2_huber = huber.score(X_te, y_te)\n",
    "\n",
    "print(\"R^2 linear regression:\", r2_lr)\n",
    "print(\"R^2 huber loss:\", r2_huber)\n",
    "\n",
    "# R2 coefficient when separating sources\n",
    "def RSS(y, y_pred):\n",
    "    return np.sum(np.square(y - y_pred))\n",
    "\n",
    "\n",
    "rss_lr_wdnwd = RSS(y_te_wdnwd, y_pred_lr_wdnwd)\n",
    "rss_baseline = RSS(y_te, y_te.mean())\n",
    "r2_lr_wdnwd = 1 - rss_lr_wdnwd / rss_baseline\n",
    "\n",
    "print(\"R^2 when separating sources:\", r2_lr_wdnwd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
