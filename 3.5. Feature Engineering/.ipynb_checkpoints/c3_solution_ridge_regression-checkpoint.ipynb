{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge regression\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution - Basic feature engineering for the house prices data\n",
    "---\n",
    "\n",
    "> **Exercise**: (A) load the house prices data from `c3_house-prices.csv` (B) plot the distribution of the continuous variables using histograms: you should see that many have a skewed one (C) create a `preprocess(df)` function which performs (C.1) one-hot encoding (C.2) fill missing values (C.3) apply a **log-transform** to every continuous feature and (C.4) add their **polynomial features** of degree 2, 3 and 0.5 (square root). Finally (D) create the X/y numpy arrays - use the `np.log10()` of the sale price as the target variable.\n",
    "\n",
    "**Hint**: The logarithm of zero doesn't exist, so we have to make sure that there are no zero values in the continuous columns when applying the log-transform. To achieve this, we can use `np.log(x+1)` (or simply `np.log1p(x)` which is equivalent) which will leave zero values untransformed i.e. `log(1)=0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# (A) Load the data\n",
    "data_df = pd.read_csv(\"c3_house-prices.csv\")\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous features from the documentation\n",
    "continuous = [\n",
    "    \"Lot Frontage\",\n",
    "    \"Lot Area\",\n",
    "    \"Mas Vnr Area\",\n",
    "    \"BsmtFin SF 1\",\n",
    "    \"BsmtFin SF 2\",\n",
    "    \"Bsmt Unf SF\",\n",
    "    \"Total Bsmt SF\",\n",
    "    \"1st Flr SF\",\n",
    "    \"2nd Flr SF\",\n",
    "    \"Low Qual Fin SF\",\n",
    "    \"Gr Liv Area\",\n",
    "    \"Garage Area\",\n",
    "    \"Wood Deck SF\",\n",
    "    \"Open Porch SF\",\n",
    "    \"Enclosed Porch\",\n",
    "    \"3Ssn Porch\",\n",
    "    \"Screen Porch\",\n",
    "    \"Pool Area\",\n",
    "    \"Misc Val\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# (B) A quick look at the distribution of the variables\n",
    "fig, axes = plt.subplots(nrows=5, ncols=4, figsize=(10, 8))\n",
    "\n",
    "for c, ax in zip(continuous, axes.ravel()):\n",
    "    ax.hist(data_df[c].dropna(), bins=30)\n",
    "    ax.set_title(c)\n",
    "\n",
    "plt.tight_layout()  # to avoid overlapping with the labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# (C) Preprocessing function\n",
    "def preprocess(df):\n",
    "    # Work on a copy\n",
    "    df = df.copy()\n",
    "\n",
    "    # (C.1) One-hot encoding\n",
    "    df = pd.get_dummies(df, dummy_na=True)\n",
    "\n",
    "    # (C.2) Fill missing values\n",
    "    for c in df.columns:\n",
    "        df[c] = df[c].fillna(df[c].median())\n",
    "\n",
    "    # (C.3) Apply log-transform\n",
    "    df[continuous] = np.log1p(df[continuous])\n",
    "\n",
    "    # (C.4) Add polynomial features\n",
    "    for c in continuous:\n",
    "        for d in [0.5, 2, 3]:\n",
    "            name = \"{}**{}\".format(c, d)\n",
    "            df[name] = df[c] ** d\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "preprocessed_df = preprocess(data_df)\n",
    "preprocessed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (D) Create X, y\n",
    "X = preprocessed_df.drop(\"SalePrice\", axis=1).values\n",
    "y = np.log10(preprocessed_df.SalePrice).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution - Tune Ridge regression\n",
    "---\n",
    "\n",
    "> **Exercise**: Fit a ridge regression model and tune its alpha value using grid search. Use the train/test set methodology with a 50/50 split. Print the optimal alpha value and the test MSE/MAE scores.\n",
    "\n",
    "**Hint**: Don't forget to standardize the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split into train/test sets\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_tr_rescaled = scaler.fit_transform(X_tr)\n",
    "X_te_rescaled = scaler.transform(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Variable to store the results\n",
    "gs_results = []\n",
    "\n",
    "# Grid search\n",
    "for alpha in np.logspace(-1, 4, num=20):\n",
    "    # Create and fit ridge regression\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_tr_rescaled, y_tr)\n",
    "\n",
    "    # Save model and its performance on train/test sets\n",
    "    gs_results.append(\n",
    "        {\n",
    "            \"model\": ridge,\n",
    "            \"alpha\": alpha,\n",
    "            \"train_mse\": MSE(y_tr, ridge.predict(X_tr_rescaled)),\n",
    "            \"train_mae\": MAE(10 ** y_tr, 10 ** ridge.predict(X_tr_rescaled)),\n",
    "            \"test_mse\": MSE(y_te, ridge.predict(X_te_rescaled)),\n",
    "            \"test_mae\": MAE(10 ** y_te, 10 ** ridge.predict(X_te_rescaled)),\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Convert results to DataFrame\n",
    "gs_results = pd.DataFrame(gs_results)\n",
    "\n",
    "# Plot the validation curves\n",
    "plt.plot(np.log10(gs_results[\"alpha\"]), gs_results[\"train_mse\"], label=\"train curve\")\n",
    "plt.plot(np.log10(gs_results[\"alpha\"]), gs_results[\"test_mse\"], label=\"test curve\")\n",
    "\n",
    "# Mark best alpha value\n",
    "best_result = gs_results.loc[gs_results.test_mse.idxmin()]\n",
    "plt.scatter(\n",
    "    np.log10(best_result.alpha), best_result.test_mse, marker=\"x\", c=\"red\", zorder=10\n",
    ")\n",
    "plt.title(\n",
    "    \"Best alpha: {:.1e} - mse: {:.4f} mae: {:,.0f}$\".format(\n",
    "        best_result.alpha, best_result.test_mse, best_result.test_mae\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.xlabel(\"$log_{10}(alpha)$\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative solution - average multiple runs\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit/test N models\n",
    "gs_results = []\n",
    "for run_idx in range(10):\n",
    "    # Split into train/test sets\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.5, random_state=run_idx)\n",
    "\n",
    "    # Standardize features\n",
    "    X_tr_rescaled = scaler.fit_transform(X_tr)\n",
    "    X_te_rescaled = scaler.transform(X_te)\n",
    "\n",
    "    # Grid search\n",
    "    for alpha in np.logspace(1, 4, num=20):\n",
    "        # Create and fit ridge regression\n",
    "        ridge = Ridge(alpha=alpha)\n",
    "        ridge.fit(X_tr_rescaled, y_tr)\n",
    "\n",
    "        # Save model and its performance on train/test sets\n",
    "        gs_results.append(\n",
    "            {\n",
    "                \"model\": ridge,\n",
    "                \"alpha\": alpha,\n",
    "                \"run_idx\": run_idx,\n",
    "                \"train_mse\": MSE(y_tr, ridge.predict(X_tr_rescaled)),\n",
    "                \"train_mae\": MAE(10 ** y_tr, 10 ** ridge.predict(X_tr_rescaled)),\n",
    "                \"test_mse\": MSE(y_te, ridge.predict(X_te_rescaled)),\n",
    "                \"test_mae\": MAE(10 ** y_te, 10 ** ridge.predict(X_te_rescaled)),\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Convert results to DataFrame\n",
    "gs_results = pd.DataFrame(gs_results)\n",
    "\n",
    "# Group results by alpha value\n",
    "gb_alpha = gs_results.groupby(\"alpha\")\n",
    "\n",
    "# Compute train/test mean scores with std\n",
    "mean_tr = gb_alpha.train_mse.mean()\n",
    "mean_te = gb_alpha.test_mse.mean()\n",
    "std_tr = gb_alpha.train_mse.std()\n",
    "std_te = gb_alpha.test_mse.std()\n",
    "alphas = mean_tr.index.values\n",
    "\n",
    "# Plot mean scores\n",
    "plt.plot(np.log10(alphas), mean_tr, label=\"train\")\n",
    "plt.plot(np.log10(alphas), mean_te, label=\"test\")\n",
    "\n",
    "# Quantify variance with Â±std curves\n",
    "plt.fill_between(np.log10(alphas), mean_tr - std_tr, mean_tr + std_tr, alpha=0.2)\n",
    "plt.fill_between(np.log10(alphas), mean_te - std_te, mean_te + std_te, alpha=0.2)\n",
    "\n",
    "# Add marker for best score\n",
    "best_alpha = mean_te.idxmin()\n",
    "plt.scatter(np.log10(best_alpha), mean_te.min(), marker=\"x\", c=\"red\", zorder=10)\n",
    "\n",
    "# Print best MSE/MAE scores\n",
    "best_result = gb_alpha.get_group(best_alpha)\n",
    "plt.title(\n",
    "    \"Best alpha: {:.1e} - mse: {:.4f} mae: {:,.0f}$\".format(\n",
    "        best_alpha, best_result.test_mse.mean(), best_result.test_mae.mean()\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.xlabel(\"$log_{10}(alpha)$\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
