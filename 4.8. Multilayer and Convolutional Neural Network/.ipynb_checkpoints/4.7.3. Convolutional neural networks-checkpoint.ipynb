{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d99b6cd-41b9-40aa-ae87-675fe61e9a28",
   "metadata": {},
   "source": [
    "### Convolutional layers\n",
    "Convolutional neural networks use a particular type of layer called convolutional layer that can work on 3-dimensional volumes of data like images. The intuition behind those convolutional layers is that the important features are usually not specific to some locations of the image. For instance, if detecting lines is an important aspect of our network, we don’t need to learn to detect lines at every location of the image independently. Instead, we could simply learn a line detector that we slide over the image. This operation is called convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22500e7e-9f3e-42d5-b4d4-475599fe1507",
   "metadata": {},
   "source": [
    "### TensorFlow implementation\n",
    "We will now see how to implement the simple convolutional neural network from above using TensorFlow.\n",
    "\n",
    "#### Data preprocessing\n",
    "Let’s start by loading and preprocessing the data. We saw in the previous unit that we can improve the learning process by centering the input values around zero. In our case, we are working with pixel values that range between 0 and 255. A common way to preprocess images before passing them to a ConvNet is to subtract 128 to each value and divide them by 255. With this simple procedure, we should get centered values that range between -0.5 and 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b6e7f7c-684c-462f-b999-592daee892fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "with np.load(\"c4_mnist-20k.npz\", allow_pickle=False) as npz_file:\n",
    "    mnist = dict(npz_file.items())\n",
    "\n",
    "# Convert pixels into floating point numbers\n",
    "data = mnist[\"data\"].astype(np.float32)\n",
    "\n",
    "# Rescale pixel values between -0.5 and 0.5\n",
    "data = (data - 128) / 255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61042e93-db7d-4e18-aeee-65e0b777d58d",
   "metadata": {},
   "source": [
    "In this code, we load the image pixels, convert them into floating point numbers and rescale them using the formula from above.\n",
    "\n",
    "In this example, we will monitor the learning process using a validation set. We will use 19,500 images for training and the remaining 500 ones for evaluation. Let’s create these train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90427227-16d0-4fdf-95c7-0d6042b2b202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (19500, 28, 28, 1) (19500,)\n",
      "Valid: (500, 28, 28, 1) (500,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    # Reshape images (28 by 28)\n",
    "    data.reshape(-1, 28, 28, 1),  # Single channel (grayscale)\n",
    "    mnist[\"labels\"],\n",
    "    test_size=500,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "# Print shape\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Valid:\", X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc34c4a8-b1a6-44c2-a9e6-a0596d604fe4",
   "metadata": {},
   "source": [
    "In this code, we reshape the flat matrix of image pixels back into 28x28x1 grids of values with the reshape() function from Numpy and get two 4-dimensional arrays of values X_train and X_test with respectively 19,500 and 500 images.\n",
    "\n",
    "Note: The last dimension, in this case representing the grayscale channel, is very important for ConvNets. It needs to be specified even if it only has a single value, as in our example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c85b8a7-46a8-4a46-9c03-b405fa5ec3c5",
   "metadata": {},
   "source": [
    "### Create the convolutional layer\n",
    "### Define the convolutional layer manually\n",
    "We want to create our first convolutional layer. To achieve this, we will use the conv2d() function from the nn module. 2d because the convolution operation is done in two dimensions, regardless of the shape of the input image and kernel (whether they are 2d or 3d). We are sliding the kernel in the height/width dimensions to get a two dimensional output. The function takes the input values and a kernel variable with the kernel weights. Note that it expects 4d tensors in both cases.\n",
    "\n",
    "* A [batch, in_height, in_width, in_channels] tensor for the input.\n",
    "* A [filter_height, filter_width, in_channels, out_channels] tensor for the kernels.\n",
    "\n",
    "We can pass the X_train from above for the input values, but we need to create the second tensor with the kernel weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "935d0ab8-4811-4c16-a0cc-e477c95073b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define kernel matrix\n",
    "kernel = tf.Variable(\n",
    "    initial_value=tf.random.truncated_normal(\n",
    "        shape=(5, 5, 1, 16),  # Sixteen 5x5x1 kernels\n",
    "        stddev=0.01,  # Small standard deviation\n",
    "        seed=0,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a903d8-9fd0-44d3-b00d-c8097b43daa4",
   "metadata": {},
   "source": [
    "In this code, we have created a Variable with the weights for the sixteen kernels and initialize it using a (truncated) normal distribution with a small standard deviation. Note that we have to specify the depth of the input values even if the images are 2-dimensional. For this reason, the shape of the kernels is 5x5x1 instead of 5x5, and the input images are 28x28x1 instead of 28x28.\n",
    "\n",
    "We can now create the convolution operation with the conv2d() function. We can specify the stride and the padding with the stride and padding arguments. For the stride, we need to provide a list with one value for each dimension in the input, i.e., how the kernels move on the [batch, in_height, in_width, in_channels] input tensor. In our case, we set it to [1, 2, 2, 1] since we are doing a 2d convolution over the height/width axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15ee6514-6b7f-4aff-b391-c0d691837594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19500, 14, 14, 16)\n"
     ]
    }
   ],
   "source": [
    "# Convolutional layer\n",
    "conv = tf.nn.conv2d(\n",
    "    X_train, kernel, strides=[1, 2, 2, 1], padding=\"SAME\"  # Stride: 2  # \"same\" padding\n",
    ")\n",
    "print(conv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3038940-1231-44e2-8da4-8175cbded53e",
   "metadata": {},
   "source": [
    "The function creates a conv operation that produces sixteen 14x14 grids of values for each image. We can then add a variable with the biases and apply the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88dff012-9af1-473e-9ea3-6f53c5b8dcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create biases (one per filter)\n",
    "biases = tf.Variable(initial_value=tf.zeros(shape=[16]))\n",
    "\n",
    "# Apply activation function\n",
    "conv = tf.nn.relu(conv + biases)  # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c71354b-9f86-4f51-91a1-f4786c1b3759",
   "metadata": {},
   "source": [
    "Note that we create one bias for each kernel and add them to the output values using the + operator. TensorFlow will automatically add each bias to the relevant filter using broadcasting.\n",
    "\n",
    "Creating convolutional layers using the code from above can quickly become complex. In particular with deep networks with several layers. For this reason, TensorFlow provides a simplified Conv2D() class in its kera.layers module that automatically creates all the variables and apply the relevant activation function. Let’s redefine our network with this class.\n",
    "\n",
    "### Define convolutional layer using built-in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3b05d4d-ca1b-4d95-bd6c-a82dbb702614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19500, 14, 14, 16)\n"
     ]
    }
   ],
   "source": [
    "# Convolutional layer\n",
    "conv_layer = tf.keras.layers.Conv2D(\n",
    "    filters=16,\n",
    "    kernel_size=(5, 5),\n",
    "    strides=(2, 2),\n",
    "    padding=\"SAME\",\n",
    "    activation=tf.nn.relu,\n",
    "    kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01, seed=0),\n",
    "    name=\"conv\",  # Add name\n",
    ")\n",
    "conv_output = conv_layer(X_train)\n",
    "\n",
    "print(conv_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63f9df96-2157-47ee-a287-6ff6c430ab68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 1, 16)\n",
      "(16,)\n"
     ]
    }
   ],
   "source": [
    "print(conv_layer.kernel.shape)\n",
    "print(conv_layer.bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a29cae7-74c0-45c7-8464-3ae45775679e",
   "metadata": {},
   "source": [
    "This time, we pass the input variable, the number of filters, the stride and padding, the activation function and an initializer for the kernel weights. It’s interesting to note that we don’t have to repeat any values. This makes the network architecture much easier to edit, e.g., change the number of kernels or their size. One can extract the weights of all the sixteen kernels using the kernel class attribute and the biases using bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d296be-8f42-499b-9f41-84b670a8b6a3",
   "metadata": {},
   "source": [
    "### Max pooling layer\n",
    "The keras.layers module also provides a MaxPool2D class to create max pooling layers. The layer takes the 4d input tensor, the pool size, the stride, and padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3d32a89-3e8c-475f-a65a-d193b63f6dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19500, 7, 7, 16)\n"
     ]
    }
   ],
   "source": [
    "# Max pooling layer\n",
    "pool_layer = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"SAME\")\n",
    "pool_output = pool_layer(conv_output)\n",
    "\n",
    "print(pool_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24f70c2-a92d-4348-a73b-634b8e612369",
   "metadata": {},
   "source": [
    "As we can see, the max pooling layer reduced by half the dimensions of the input in the height/width axes and hence by 75% the number of values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea1a901-48fe-4c3e-95c4-74d7a93ab096",
   "metadata": {},
   "source": [
    "### Convolutional neural network\n",
    "Let’s add the second convolutional and max pooling layers on top of the first ones with the Conv2D() and MaxPool2D classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6ae2ce9-dd78-4f3d-b112-042d0ccb0764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19500, 7, 7, 16)\n",
      "(19500, 4, 4, 16)\n"
     ]
    }
   ],
   "source": [
    "# 2nd convolutional layer\n",
    "conv_layer2 = tf.keras.layers.Conv2D(\n",
    "    filters=16,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding=\"SAME\",\n",
    "    activation=tf.nn.relu,\n",
    "    kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01, seed=0),\n",
    "    name=\"conv2\",\n",
    ")\n",
    "conv_output2 = conv_layer2(pool_output)\n",
    "\n",
    "# 2nd max pooling layer\n",
    "pool_output2 = pool_layer(conv_output2)\n",
    "\n",
    "print(conv_output2.shape)\n",
    "print(pool_output2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe4545f-7334-4697-b97f-8dfd283f065b",
   "metadata": {},
   "source": [
    "This time, the convolutional layer doesn’t modify the dimension of the input since it uses the “same” padding strategy with a stride of 1. On the other hand, the max pooling layer reduces its dimensions, and we get sixteen 4x4 grids (256 output values). In a typical ConvNet architecture, we use these high-level features to solve our task. In our example, we will combine these values into ten output logits with a fully-connected layer.\n",
    "\n",
    "But first, we need to flatten the 4x4x16 output volumes into flat vectors. To achieve this we can use the reshape() function from TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13450b7c-39a2-45e6-abc0-10bc80db597a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19500, 256)\n"
     ]
    }
   ],
   "source": [
    "# Flatten output into a (batch_size, 256) matrix\n",
    "flat_output = tf.reshape(pool_output2, [-1, 256])\n",
    "\n",
    "print(flat_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b2cb12-1f60-4a68-8fa4-5769f24f12d9",
   "metadata": {},
   "source": [
    "In this code, we pass the desired output shape to the function. This can be an issue in practice since it depends on the current ConvNet architecture. In particular, we would need to recompute and edit the number of features each time we modify the first convolutional and max pooling layers, e.g., increase the number of kernels, change their size and so on.\n",
    "\n",
    "To avoid this, we can use the Flatten class from the keras.layers module which automatically computes the shape of the input and flattens the dimensions (except the first one which is the batch size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb021e25-2c42-4e09-b218-27b7c5e1efc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19500, 256)\n"
     ]
    }
   ],
   "source": [
    "# Flatten output\n",
    "flat_layer = tf.keras.layers.Flatten()\n",
    "flat_output = flat_layer(pool_output2)\n",
    "\n",
    "print(flat_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414cf01c-58b7-49c9-a5a6-b287e113df81",
   "metadata": {},
   "source": [
    "Now that we have a set of 256 features for each image, let’s build the final classifier using a fully-connected layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68f35097-3e95-41d1-97aa-4c62652a9f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19500, 10)\n"
     ]
    }
   ],
   "source": [
    "# Output layer\n",
    "logits_layer = tf.keras.layers.Dense(\n",
    "    units=10,\n",
    "    activation=None,  # No activation function\n",
    "    kernel_initializer=tf.keras.initializers.VarianceScaling(scale=1, seed=0),\n",
    "    bias_initializer=tf.zeros_initializer(),\n",
    "    name=\"dense\",\n",
    ")\n",
    "logits_output = logits_layer(flat_output)\n",
    "\n",
    "print(logits_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3104ae-63b0-477d-8703-9d7baf7e501f",
   "metadata": {},
   "source": [
    "#### Loss function and training operations\n",
    "Finally, let’s define the loss function and the training operations. This time, we will use the Adam optimizer. Adam is a very popular algorithm that was introduced in 2015. It’s now one of the default choices to optimize neural networks. We won’t go into the details of how the algorithm works, but one of the key differences with stochastic gradient descent (SGD) is that it maintains a different learning rate for each parameter in the network.\n",
    "\n",
    "Adam optimizer has several parameters, but we will only adjust the principal learning rate. We will use the default learning rate of 0.001 from the documentation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9018d8e5-11b6-4e52-b91b-a569321c7356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# Define functions used to train the graph\n",
    "\n",
    "# Compute the logits\n",
    "@tf.function\n",
    "def compute_logits(x):\n",
    "    conv_output = conv_layer(x)\n",
    "    pool_output = pool_layer(conv_output)\n",
    "    conv_output2 = conv_layer2(pool_output)\n",
    "    pool_output2 = pool_layer(conv_output2)\n",
    "    flat_output = flat_layer(pool_output2)\n",
    "    logits_output = logits_layer(flat_output)\n",
    "    return logits_output\n",
    "\n",
    "\n",
    "# Compute the loss\n",
    "@tf.function\n",
    "def compute_loss(y, logits):\n",
    "    ce = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    mean_ce = tf.reduce_mean(ce)\n",
    "    return mean_ce\n",
    "\n",
    "\n",
    "# Compute the accuracy\n",
    "@tf.function\n",
    "def compute_accuracy(y, logits):\n",
    "    predictions = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
    "    is_correct = tf.equal(y, predictions)\n",
    "    acc = tf.reduce_mean(tf.cast(is_correct, dtype=tf.float32))\n",
    "    return acc\n",
    "\n",
    "\n",
    "# Train the model (optimization procedure)\n",
    "@tf.function\n",
    "def train(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = compute_logits(x)\n",
    "        loss = compute_loss(y, logits)\n",
    "    # Concatenate the trainable variables in one list using the '+' operation on lists\n",
    "    variables = (\n",
    "        conv_layer.trainable_variables\n",
    "        + conv_layer2.trainable_variables\n",
    "        + logits_layer.trainable_variables\n",
    "    )\n",
    "    optimizer.minimize(loss=loss, var_list=variables, tape=tape)\n",
    "    return logits, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06b86f5-c293-4286-9f89-87c2789b9319",
   "metadata": {},
   "source": [
    "The main difference from the previous unit is in the compute_logits() function where we are now using the layers created above to build our convolutional neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904b1e22-57c4-4287-aea3-65bb8ecf50ce",
   "metadata": {},
   "source": [
    "### Train network\n",
    "Let’s train our network. We will use the random batch generator from the previous unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe95977d-6458-4f3f-b2e4-bb3a79943a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch generator\n",
    "def get_batches(X, y, batch_size):\n",
    "    # Shuffle X,y\n",
    "    shuffled_idx = np.arange(len(y))  # 1,2,...,n\n",
    "    np.random.shuffle(shuffled_idx)\n",
    "\n",
    "    # Enumerate indexes by steps of batch_size\n",
    "    # i: 0, b, 2b, 3b, 4b, .. where b is the batch size\n",
    "    for i in range(0, len(y), batch_size):\n",
    "        # Batch indexes\n",
    "        batch_idx = shuffled_idx[i : i + batch_size]\n",
    "        yield X[batch_idx], y[batch_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4d9382-19d3-4610-a5b7-07ad1eb551ba",
   "metadata": {},
   "source": [
    "We can now train our network for ten epochs using small batches of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22aee99c-bb43-4edb-9871-b9e40f648d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - valid: 0.922 train: 0.752 (mean)\n",
      "Epoch 2 - valid: 0.956 train: 0.937 (mean)\n",
      "Epoch 3 - valid: 0.962 train: 0.952 (mean)\n",
      "Epoch 4 - valid: 0.968 train: 0.960 (mean)\n",
      "Epoch 5 - valid: 0.972 train: 0.967 (mean)\n",
      "Epoch 6 - valid: 0.970 train: 0.970 (mean)\n",
      "Epoch 7 - valid: 0.976 train: 0.974 (mean)\n",
      "Epoch 8 - valid: 0.976 train: 0.975 (mean)\n",
      "Epoch 9 - valid: 0.974 train: 0.976 (mean)\n",
      "Epoch 10 - valid: 0.982 train: 0.980 (mean)\n"
     ]
    }
   ],
   "source": [
    "# Validation accuracy\n",
    "valid_acc_values = []\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Train several epochs\n",
    "for epoch in range(10):\n",
    "    # Accuracy values (train) after each batch\n",
    "    batch_acc = []\n",
    "\n",
    "    # Get batches of data\n",
    "    for X_batch, y_batch in get_batches(X_train, y_train, 64):\n",
    "        # Run training\n",
    "        batch_logits, _ = train(X_batch, y_batch)\n",
    "\n",
    "        # Evaluate training accuracy (on current batch)\n",
    "        acc = compute_accuracy(y_batch, batch_logits)\n",
    "        batch_acc.append(acc)\n",
    "\n",
    "    # Evaluate validation accuracy (on the whole data)\n",
    "    valid_logits = compute_logits(X_valid)\n",
    "    valid_acc = compute_accuracy(y_valid, valid_logits)\n",
    "    valid_acc_values.append(valid_acc)\n",
    "\n",
    "    # Print progress\n",
    "    print(\n",
    "        \"Epoch {} - valid: {:.3f} train: {:.3f} (mean)\".format(\n",
    "            epoch + 1, valid_acc, np.mean(batch_acc)\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Get 1st conv. layer kernels\n",
    "kernels = conv_layer.kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2c86dd-8eb6-4a10-a2da-ad3f8be98c6c",
   "metadata": {},
   "source": [
    "In this code, we run the training operation and save the accuracy on each batch of data. After each epoch, we evaluate the network on the validation set and compare its validation accuracy to the mean of the train accuracy values. In our case, the train and validation accuracy values are close to each other which is a good sign that the network is not overfitting. At the end of the training process, we save the weights of the kernels from the first convolutional layer in a kernels variable to visualize them.\n",
    "\n",
    "But first, let’s plot the validation accuracy values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "933e8e0e-33a5-415f-8748-97dd24d4e99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot accuracy values\n",
    "plt.plot(valid_acc_values)\n",
    "plt.title(\n",
    "    \"Validation accuracy: {:.3f} (mean last 3)\".format(\n",
    "        np.mean(valid_acc_values[-3:])  # Last three values\n",
    "    )\n",
    ")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ea5a68-bc4a-4d15-9c50-c90a62e0531d",
   "metadata": {},
   "source": [
    "We get a final validation accuracy around 98%.\n",
    "\n",
    "### Plot filters\n",
    "Let’s visualize the 16 kernels from the first layer. To achieve this, we need to extract the 5x5 kernel weights from the kernels variable which is an array of shape (5, 5, 1, 16)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17d88657-2a3a-4b83-9178-0cd7fddc332b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create figure with subplots\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(8, 8))\n",
    "\n",
    "# Plot the 16 kernels from the first convolutional layer\n",
    "for i, axis in enumerate(axes.flatten()):\n",
    "    # Get i-th kernel\n",
    "    kernel = kernels[:, :, :, i].numpy()\n",
    "\n",
    "    # Kernels are 5x5x1 (height, width, channels)\n",
    "    # Remove last dimension\n",
    "    kernel = kernel[:, :, 0]  # (5, 5) kernel\n",
    "\n",
    "    # Plot kernel with imshow()\n",
    "    axis.set_title(\"kernel {}\".format(i + 1))\n",
    "    axis.imshow(kernel, cmap=plt.cm.gray_r)\n",
    "    axis.get_xaxis().set_visible(False)  # disable x-axis\n",
    "    axis.get_yaxis().set_visible(False)  # disable y-axis\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60a6e96-a418-4646-ae86-f6fd2c1e990e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:adsml] *",
   "language": "python",
   "name": "conda-env-adsml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
